---
title: 'Análisis de Datos: Precio de los coches en la India'
author: "Amanda del Álamo & Alejandro Delgado"
date: "16/11/2021"
output:
  html_document:
    theme: paper
    highlight: zenburn
    code_folding: hide
    toc: yes
    toc_float: yes
    toc_depth: 1
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '1'
---

```{r setup, include=FALSE, warning=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, include = FALSE}
library(dplyr)
library(readr)
library(mice)
library(stringr)
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(gmodels)
library(Hmisc)
library(ggthemes)
library(ellipse)
library(corrplot)
library(ggcorrplot)
library(corrplot)
library(leaps)
library(PerformanceAnalytics)
library(GGally)
library(psych)
library(carData)
library(car)
library(lmtest)
library(olsrr)
library(performance)
library(see)
library(lme4)
library(patchwork)
```

# DATASET

```{r Carga de datos, message=FALSE, warning=FALSE}
data <- read.csv("cochesdataP.csv", na = c("","NA","NULL",NULL,"  ","/n" ))
head(data)
```

# DEFINICIÓN DE OBJETIVOS

Este dataset contiene toda la información acerca de un comercio de venta de coches usados en la India. Nuestro objetivo es predecir, a través de las características de un coche, cuanto nos costaría comprarlo.


# ANÁLISIS EXPLORATORIO INICIAL

La función glimpse() del paquete dplyr puede utilizarse para ver las columnas del conjunto de datos y mostrar alguna porción de ellos con respecto a cada atributo que pueda caber en una sola línea.

```{r Tipos de variables,  message=FALSE, warning=FALSE}
glimpse(data)
```

Con esta forma de visualización podemos observar mejor la naturaleza de los datos. Tenemos 6019 observaciones y 14 columnas y a simple vista vemos que muchos datos están bien tipados pero otros habrá que transformarlos, como puede ser el caso de la variable Mileage (Kilometraje) que está como Character ya que viene el número con su unidad de medida y habrá que decidir si ponerlo todo como km/kg o kmpl. Lo mismo nos pasa con Power (potencia) y New Price que parece tener muchos elementos faltantes. La variable Seats (asientos) es un double cuando debería ser entera... Hay muchas cosas que modificar para dar valor a estos datos.

1. Name: Nombre de las marcas y modelos de los coches.
2. Location: La ubicación en la que se vende el coche o está disponible para su compra.
3. Year: El año del modelo de coche.
4. Kilometers_Driven: El total de kilómetros recorridos en el coche por el anterior propietario en Km
5. Fuel_Type: El tipo de combustible utilizado por el coche.
6. Transmission: El tipo de transmisión utilizado por el coche.
7. Owner_Type: Indica si el coche es de primera, segunda, tercera, cuarta... mano.
8. Mileage: El kilometraje estándar ofrecido por la compañía de automóviles en kmpl o km/kg.
9. Engine: La cilindrada del motor en cc.
10. Power: La potencia máxima del motor en bhp (CV).
11. Seats: Número de asientos.
12. New_Price: El precio del coche, nuevo.
13. Price: El precio del coche usado en INR Lakhs (Rupias).


Con la función anterior hemos podido apreciar que hay datos que contienen diferentes tipos de unidades. Vamos a ver cuales son y como se dividen antes de limpiar los datos para luego saber como podemos tratarlas.

## Relación entre unidades {.tabset .tabset-fade .tabset-pills}

### Mileage

```{r , message=FALSE, warning=FALSE}
data %>% pull(Mileage) %>% 
  str_split(" ", simplify=TRUE) %>% 
  cbind(data$Fuel_Type) %>% 
  subset(select=2:3) %>% 
  as.data.frame() %>% table() #Extraigo los diferentes tipos que hay y como se relacionan
```

### Engine

```{r , message=FALSE, warning=FALSE}
data %>% pull(Engine) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table() # hago lo mismo para confirmar que solo hay un tipo
```

### Power

```{r , message=FALSE, warning=FALSE}
data %>% pull(Power) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table() # hago lo mismo para confirmar que solo hay un tipo
```

### New Price

```{r , message=FALSE, warning=FALSE}
data %>% pull(New_Price) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table()
```

## {-}

Podemos observar que en Mileage y New_Price tenemos diferentes tipos de unidades.
Las diferentes unidades en Mileage tienen que ver con el tipo de combustible y las de New_Price se dividen en Rupias (Lakh) y Colón (Cr)
Más adelante dividiremos en dos variables distintas.

```{r Modificación de datos, results = TRUE, message=FALSE, warning=FALSE}
data %>% mutate(Mileage = as.numeric(str_extract(Mileage, "^[:graph:]+"))) -> data
data %>% mutate(Engine = as.numeric(str_extract(Engine, "^[:graph:]+"))) -> data
data %>% mutate(Power = as.numeric(str_extract(Power, "^[:graph:]+"))) -> data
data %>%
  mutate(Seats = as.integer(Seats)) -> data
data %>%
  mutate(Fuel_Type = as.factor(Fuel_Type)) %>%
  mutate(Transmission = as.factor(Transmission)) %>%
  mutate(Location = as.factor(Location)) %>%
  mutate(New_Price = as.numeric(str_extract(New_Price, "^[:graph:]+"))) -> data
data %>% mutate(Owner_Type = factor(Owner_Type, levels=c("First", "Second", "Third", "Fourth & Above"))) -> data
```

Hemos cambiado el tipo de variable de algunas de las columnas ya que no era el adecuado. A la variable Power se le introducen NA's por coerción debido a que tiene algun valor recogido como NA.
También hemos modificado la grafía del dato ya que venían con las unidades en el registro.

# SEPARACION TRAIN/TEST

Procedemos a separar el dataset en sets de *_train_* y de *_test_*

```{r train test sets, message=FALSE, warning=FALSE} 
# 80% del tamaño de la muestra
smp_size <- floor(0.8 * nrow(data))
# establecemos la semilla para que su partición sea reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
rm(train_ind)
```


## Análisis variable "Year" {.tabset .tabset-fade .tabset-pills}

### Histograma

```{r , message=FALSE, warning=FALSE}
hist(train$Year)
```

### Boxplot

```{r , message=FALSE, warning=FALSE}
boxplot(train$Year, horizontal = TRUE)
```


### Histograma + Densidad

```{r, , message=FALSE, warning=FALSE}
ggplot(train, aes(x=Year)) + 
  geom_histogram(breaks=seq(1996,2020,by=1),aes(y=..density..), binwidth = 0.4,  fill="blue", colour="black") +
  geom_density(colour="green", fill="green",alpha=0.3)
```

## {-}

La primera variable que vamos a analizar es "Year", hace referencia al año en que se fabricó cada coche. 
Se trata de una variable cuantitativa, ya que podemos calcular la diferencia entre fechas, en la que aparecen los años desde 1996 hasta 2018.
Obtenemos que en el año 1998 se contabilizan 10 coches, en el año 2000, 23, en el 2004, 135. 
Va aumentando el número de coches progresivamente con el paso de los años hasta llegar a 2016 donde vuelve a disminuir también progresivamente. Esta variable está definida como "integer" y así la trataremos, ya que no nos da problema y nos aporta toda la información necesaria. 
Además, gracias al boxplot se aprecia que el 50% de los datos se encontrarán entre 2011 y 2017.

## Análisis variable "Kilometers_driven" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Kilometers_driven , message=FALSE, warning=FALSE}
summary(train$Kilometers_Driven)
```

### Histograma + Densidad

```{r , message=FALSE, warning=FALSE}
train %>% ggplot(aes(x=Kilometers_Driven)) +
  ggtitle("Kilómetros recorridos") +
  theme_fivethirtyeight() +
  geom_histogram(aes(y=..density..), color="white", fill="dark blue", bins = 50) + 
  geom_density() +
  scale_x_log10()
```

## {-}

La segunda variable a analizar es "Kilometers_driven", que hace referencia a los kilometros que lleva recorridos el coche. Se trata de una variable cuantitativa expresada como integer en nuestros datos. El mínimo de kilometros recorridos por un coche de los que estamos estudiando es de 171 mientras que el máximo llega hasta 6500.000. Analizándolo al detalle se aprecia que el valor máximo es un outlier ya que está muy lejos de la media y es el único coche con tantos km recorridos. Más adelante, decidiremos que hacer con ese valor, de momento, obtenemos que la media de kilometros recorridos por los coches es de 58738 y que el 50% de los datos se encuentran entre 53000 y 73000. Además hemos aplicado escala logarítmica en el histograma para una mejor visualización.

```{r}
train %>% filter(Kilometers_Driven>4e5)
```
Es llamativo que un coche del año 2017 tenga 6500000 kilómetros recorridos, pero puede ser posible, así que lo dejamos así. 

## Análisis variable "Fuel_Type" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Fuel_Type , message=FALSE, warning=FALSE}
summary(train$Fuel_Type)
```

### Histograma

```{r , message=FALSE, warning=FALSE}
ggplot(train, aes(x=Fuel_Type)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black", ) 
```

## {-}

La tercera variable que vamos a analizar es "Fuel_Type", que hace referencia al tipo de combustible que usa cada coche. Se trata de una variable cualitativa. Está representada en nuestros datos como factor y los valores que  toma son CNG,LPG, Electric, Diesel y Pretol. Vamos a describir cada uno de los valores que toma esta variable:

  -CNG: El gas natural comprimido, más conocido por la sigla GNC, es un combustible para uso vehicular que, por ser económico y ambientalmente más limpio, es considerado una alternativa sustentable para la sustitución de combustibles líquidos.
    
  -LPG: El gas licuado del petróleo es la mezcla de gases licuados presentes en el gas natural o disueltos en el petróleo. Lleva consigo procesos físicos y químicos por ejemplo el uso de metano.
    
  -Diésel: El diésel o dísel, también denominado gasóleo o gasoil, es un hidrocarburo líquido de densidad sobre 850 kg/m³, compuesto fundamentalmente por parafinas y utilizado principalmente como combustible en calefacción y en motores diésel. Su poder calorífico inferior es de 35,86 MJ/l.
    
  -Petrol: La gasolina es formada con el petróleo refinado, utilizado principalmente como combustible, es esencial para la red mundial de transporte, el combustible primario que hace funcionar los motores de combustión interna que mueven la mayoría de los automóviles y otros sistemas de transporte.
    
De Electric, eléctricos es del tipo que menos muestras poseemos, sólo 2. De LPG y CNG también poseemos pocas (1 y  56 restivamente) y es en Diesel y Petrol donde tenemos la mayoría de los datos, siendo 3852 y 3325 las muestras respectivamente. 
Se muestra el histograma para visualizar la gran diferencia de muestras entre Diesel y Petróleo y las demás.


## {-}

## Análisis variable "Location" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Location , message=FALSE, warning=FALSE}
summary(train$Location) 
```

### Histograma

```{r , message=FALSE, warning=FALSE}
ggplot(train, aes(x=Location)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black")
```

## {-}

Otra de las variables es Location, que es la localización en que está disponible el coche para vender. Se trata de una variable cuantitativa que catalogamos como factor para estudiarla en función de las muestras que posea cada ciudad. La que menos coches disponibles tiene por el momento es Ahmedabad con 224 y le secunda Bangalore con 358 y por el otro extremo, tenemos a la ciudad de Hyderabad con 742 y Mumbai con el máximo de coches disponibles, 790. 

## Análisis variable "Transmission" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Transmission, message=FALSE, warning=FALSE}
summary(train$Transmission)
```

### Histograma

```{r, message=FALSE, warning=FALSE}
ggplot(train, aes(x=Transmission)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black", ordered=TRUE)
```

## {-}

Seguimos con el análisis univariante, ahora con "Transmission". Se trata de una variable cualitativa binaria, en la que podemos distinguir entre los coches automáticos y manuales. Una transmisión manual es una caja de cambios que no puede alterar la relación de cambio por sí sola, requiriendo la intervención del conductor para hacer esto y sin embargo, una transmisión automática es una caja de cambios de automóviles u otro tipo de vehículos que puede encargarse por sí misma de cambiar la relación de cambio automáticamente a medida que el vehículo se mueve, liberando así al conductor de la tarea de cambiar de marcha manualmente. Se tienen  muestras 1720 de automáticos y 4299 de manuales. Tenemos la variable como factor en nuestros datos, en este caso, al ser sólo dos valores, es perfecto para nuestro análisis.


## Análisis variable "Owner_Type" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r , message=FALSE, warning=FALSE}
summary(train$Owner_Type)
```

### Histograma

```{r analisis variable Owner_Type, message=FALSE, warning=FALSE}
ggplot(train, aes(x=Owner_Type)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black")
```

## {-}

La siguiente variable a analizar es "Owner_Type", que hace referencia a la clase de propietario, es decir, si el conductor está configurado como primer, segundo o tercero. Se trata de una variable cualitativa en la que podemos distinguir entre los valores: First, Second, Third y Fourth&Above. Del valor que menos muestras tenemos es Fourth&Above con 9 de ellas, después, Third con 113, y en Second y First aumentan considerablemente (968 y 4929, respectivamente) por lo que será mucho más preciso el análisis a la hora de correlacionar variables. Realizamos el histograma para apreciar la diferencia entre el número de muestras de cada tipo.

## Análisis variable "Mileage" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Mileage, message=FALSE, warning=FALSE}
summary(train$Mileage)
```

### Boxplot

```{r, message=FALSE, warning=FALSE}
boxplot(train$Mileage, col = "blue")
```

## {-}

Seguimos con el análisis univariante de la variable "Mileage" que hace referencia al kilometraje del coche y está expresado en kilómetros por litro. Se trata de una variable cuantitativa continua que toma muchos y distintos valores que posteriormente agruparemos por intervalo. En nuestros datos está expresada como factor, lo mejor sería convertirlo a integer o float para así poder realizar gráficos para visualizar cada una de las muestras. No tiene sentido trabajarla como factor pero la trabajaremos más adelante. Tampoco se ha realizado el gráfico porque visualmente no ayuda.

## Análisis variable "Engine" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Engine, message=FALSE, warning=FALSE}
summary(train$Engine)
```

### Boxplot

```{r, message=FALSE, warning=FALSE}
boxplot(train$Engine, col = "blue")
```

## {-}

Esta variable, "Engine", hace referencia a la cilindrada del motor. Se trata de una variable cuantitativa discreta y que está como integer en nuestros datos. El mínimo es 72 y el máximo es 5998 siendo la media 1621 y donde el 50% de las muestras las encontramos entre 1198 y 1984.

## Análisis variable "Power" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Power, message=FALSE, warning=FALSE}
summary(train$Power)
```

### Boxplot

```{r , message=FALSE, warning=FALSE}
boxplot(train$Power, col = "blue")
```

## {-}

Esta variable hace referencia a la potencia del motor. Se trata de una variable cuantitativa continua en la que el mínimo es 34.2 y el máximo 560 con media 113.3 y donde el 50% de los datos se encuentran entre 75 y 138. Además, existen 113 valores faltantes que serán de gran importancia en nuestro análisis.

## Análisis variable "Seats" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Seats , message=FALSE, warning=FALSE}
summary(train$Seats)
```

### Histograma

```{r , message=FALSE, warning=FALSE}
hist(train$Seats, col = "blue")
```

### Asientos = 0

No tiene sentido que haya coches con 0 asientos, procedemos a su eliminación

```{r, message=FALSE, warning=FALSE}
train%>% filter(Seats>0) -> train
summary(train$Seats)
```
## {-}

Esta variable "Seats" hace referencia al número de asientos que tiene el coche. Es una variable cuantitativa discreta ya que son valores exactos y además se trata como numeric, que viene perfecto para nuestro análisis. Se aprecia que aparece una de las opciones con Seats=0 cuyo valor es NA, la hemos obviado ya que es imposible que un coche no tenga asientos. La mayoría de los coches poseen 5 asientos y se le acercan también los coches de 7 y 8 plazas, mucho más comunes en personas con muchos hijos o que necesiten los coches para transportar más personas de lo "común".
Si nos fijamos en el summary como hemos dicho antes la media está en 5.28, aproximadamente 5 y contamos con 34 valores NA's.

## Análisis variable "New_Price" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable New_price, message=FALSE, warning=FALSE}
summary(train$New_Price)
```

### NA's %

```{r, message=FALSE, warning=FALSE}
apply(is.na(train[, c(12,13)]), 2, mean)  #porcentaje na por columna 
```

## {-}

New_Price contiene 4105 NA's que conforman el 86% de los valores faltantes en esa columna. Más adelante la eliminaremos del train set cuando hagamos la división.

## Análisis variable "Price" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Price, message=FALSE, warning=FALSE}
summary(train$Price)
```

### Histograma + Densidad

Visualizamos Price en escala logaritmica.

```{r, message=FALSE, warning=FALSE}
train%>% ggplot(aes(x=Price)) +
  ggtitle("Precio") +
  theme_fivethirtyeight() +
  geom_histogram(aes(y=..density..), color="white", fill="dark blue", bins = 50) + 
  geom_density() +
  scale_x_log10()
```

## {-}

La variable Price será nuestra variable respuesta. Trataremos de estimar el precio de un coche en base a todas las demás características. El precio está expresado en Rupias y en nuestros datos como numeric. Haciendo un summary vemos que el mínimo precio es de 0.440 y el máximo de 160 que al estar tan lejos de la media se entiende que hay pocos coches que tengan un precio tan alto. La media está en 9.47 rupias y el 50% de los coches tienen un precio de entre 3.5 y 9.92. 

Una vez analizadas tanto las variables de manera univariante como sus outliers, ahora ya podemos detectar y tratar los valores faltantes.




# DETECCIÓN, TRATAMIENTO E IMPUTACIÓN DE DATOS 

## {.tabset .tabset-fade .tabset-pills}

### Tabla NA's

A continuación vamos a ver la cantidad de valores perdidos con la función md.pattern de la librería *mice*

```{r missing data, results='hide', message=FALSE, warning=FALSE}
md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

### NA's por columna

Vamos a buscar en qué variables y en qué medida de nuestro conjunto de datos hay algún dato del tipo `NA`

Porcentaje de NA's por columna

```{r encontrar NAs en el caso de que aparezcan en nuestro conjunto, message=FALSE, warning=FALSE}
apply(is.na(train), 2, mean) #porcentaje NA por columna  
#apply(is.na(train), 2, which)  # Posición de NA por columna
#p= dim(train)[2]
#number_na = apply(train[,c(p-1,p)],1,function(x) sum(is.na(x)))
#table(number_na)
```
Número de NA's por columna

```{r , message=FALSE, warning=FALSE}
colSums(is.na(train))
```

Se observa claramente que al 86% de los registros les falta datos de la variable New_price, por lo que vamos a proceder a su eliminación ya que la imputación de NA es inviable. También eliminaremos la columna 'X' ya que no es más que el indice duplicado.

### Eliminación Columnas

Eliminamos las columnas New_Price y X
```{r , message=FALSE, warning=FALSE}
train %>% select(-New_Price) -> train
train %>% select(-X) -> train
```

Podemos volver a analizar los valores faltantes ahora que hemos eliminado la columna New_Price

```{r missing data2, results='hide', message=FALSE, warning=FALSE}
md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

Como podemos ver ahora:
-85 coches que tienen valores faltantes en las columnas Power
-2 coches que no tienen datos de Mileage

### Datos faltantes

Los datos faltantes se podrían rellenar buscando información en internet o completandolos con los datos de coches con el mismo nombre. Vamos a probar esto.

```{r, message=FALSE, warning=FALSE}
train %>% filter(is.na(Engine) | is.na(Seats) | is.na(Power) | is.na(Mileage)) %>% 
  pull(Name) %>% unique() -> missing_cars #guardamos los coches que tienen faltantes
train %>% group_by(Name) %>% 
  fill(Engine, Power, Seats, Mileage) %>% ungroup() -> train #sacamos de data esos coches

md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

Se puede apreciar que el número de valores faltantes disminuye pero no de forma significativa. Aún tenemos más de 70 coches con valores faltantes y dado que la mayoría tiene muchas especificaciones dentro de su propio nombre, buscar los valores que faltan coche por coche es tedioso y puede que no afecte mucho al resultado final del análisis. 
Procedemos a eleminiar todos los registros con valores faltantes en lugar de imputarlos.

```{r, message=FALSE, warning=FALSE}
train %>% drop_na() -> train
```

## {-}


# TRANSFORMACIÓN Y CREACIÓN DE VARIABLES 

## {.tabset .tabset-fade .tabset-pills}

### Variable Make

Por lo antes comentado de los nombres, vamos a crear una nueva variable llamada *Make*, la razón de crear esta variable es la de separar la Marca del tipo de coche ya que ambos estan juntos en la variable *Name*.

```{r new variable, message=FALSE, warning=FALSE}
str_split(train$Name, " ", simplify=TRUE) %>% subset(select=1) %>% unique() -> car_makes
car_makes[car_makes=="Land"] <- "Land Rover" #Anomalía en los datos
car_makes_regex <- paste(car_makes, collapse="|")
str_extract(train$Name, car_makes_regex) -> make
train %>% mutate(Make = str_to_title(make)) -> train
```

```{r}
#Hacemos una divisíón de los coches por marca en cuanto a si son de gama baja, media o alta
train %>% 
  mutate(
    Gama = case_when( 
      train$Make=="Datsun" |train$Make=="Smart" |train$Make=="Tata" |train$Make=="Fiat" |train$Make=="Chevrolet" |train$Make=="Ambassador" ~ "Gama baja",
      train$Make=="Skoda"|train$Make=="Renault" |train$Make=="Ford" |train$Make=="Honda"|train$Make=="Volkswagen" |train$Make=="Hyundai" |train$Make=="Nissan" |train$Make=="Maruti" ~ "Gama media",
      train$Make=="Bentley"|train$Make=="Porsche" |train$Make=="Land Rover" |train$Make=="Jaguar" |train$Make=="Mini" |train$Make=="Mercedes-Benz" |train$Make=="Audi" |train$Make=="Bmw" |train$Make=="Jeep" |train$Make=="Volvo" |train$Make=="Isuzu" |train$Make=="Mitsubishi" |train$Make=="Toyota" |train$Make=="Force" |train$Make=="Mahindra"~ "Gama alta"
    )
  ) -> train

train$Gama <- as.factor(train$Gama)
```
### Variables Kmpl y Kmpkg

Al inicio detectamos que había dos unidades de medida en la variable Mileage.

Los kmpkg son en realidad una métrica para los combustibles de gas licuado. Así que no está justificado convertirlos en unidades de kmpl. 
Los coches eléctricos ni siquiera tienen la métrica del kilometraje en este conjunto de datos, algo que es de esperar.

Por lo tanto, vamos a crear dos variables llamadas kmpkg y kmpl, para que la variable Mileage pueda tener diferentes coeficientes para los tipos de combustible diesel/gasolina y GNC/GLP. 
La lógica es que kmpkg sólo tendrá valores no nulos para los coches alimentados con GNC/GPL, por lo que los coeficientes se ajustarán/aprenderán sólo de esas observaciones y viceversa.

```{r, message=FALSE, warning=FALSE}
train %>% 
    mutate(kmpl = ifelse(Fuel_Type=="Diesel" | Fuel_Type=="Petrol", Mileage, 0)) %>%
    mutate(kmpkg = ifelse(Fuel_Type=="CNG" | Fuel_Type=="LPG", Mileage, 0)) %>%
    select(-Mileage) -> train
```

## {-}

# SELECCIÓN DE VARIABLES 

## {.tabset .tabset-fade .tabset-pills}

### Variable Respuesta

Nuestra variable respuesta va a ser: *Price*.

Por lo que en primer lugar, vamos a ver la distribución de esta variable.

```{r, message=FALSE, warning=FALSE}
train %>% ggplot() + 
  geom_histogram(aes(Price, ..density..), bins=80) + 
  geom_density(aes(Price))
```

La distrubución es demasiado sesgada, volvemos a probar usando una distribución logaritmica

```{r, message=FALSE, warning=FALSE}
train %>% ggplot() + 
  geom_histogram(aes(Price, ..density..), bins=80) + 
  geom_density(aes(Price)) +
  scale_x_log10()
```

Esto remedia la asimetría, por lo que transformaremos la variable antes de modelarla. Para la exploración seguiremos utilizando la escala logarítmica, pero no transformaremos realmente la variable *Price* en el conjunto de datos.

### Correlación 

Para analizar la correlación entre variables mostramos tres gráficos (utilizando las librerías `ellipse` y `corrplot`):

- En el primero lo que haremos será ver la correlación con elipses. Cuanto más circular sea menos correlación habrá entre las variables y cuanto más recta más correlación habrá.

- En el segundo lo que haremos será ver la correlación con una escala numérica de 0 a 1. El 0 indica ausencia de relación lineal y el 1 indica relación lineal perfecta.

- En el tercero, usando la escala que tenemos en el lateral, vemos que cuanto más oscuro y grande es el círculo, mayor relación lineal hay (azul si es positiva y rojo si es negativa), y cuanto más claro y pequeño es el círculo, menor relación lineal hay (azul si es positiva y rojo si es negativa).

Lo hacemos únicamente, de momento, con las variables numéricas.

```{r corr 2, message=FALSE, warning=FALSE}
corrplot(cor(train[, c(3,4, 8, 9, 11, 14, 15)]), method = "ellipse") 
corPlot(train[, c(3,4, 8, 9, 11, 14, 15)], cex = 1.2, main = "Matriz de correlación")
corrplot(cor(train[, c(3,4, 8, 9, 11, 14, 15)]),method = "circle",       order = "hclust",         hclust.method = "ward.D",
         addrect =2,rect.col = 3,rect.lwd = 3)  
```

Con estos gráficos podemos ver rápidamente cuáles son las variables más correlacionadas con la variable respuesta y entre ellas mismas. Las que más pueden afectar a nuestra variable respuesta son Engine y Power. Year y kmpl tienen una correlación de 0.3 y sin embargo kmpkg no tiene nada de correlación al igual que los kilómetros recorridos que tenga el coche por lo que no servirán de mucho para nuestro análisis.

Vemos más detalladamente la correlación con cada variable, esta parte es fundamental para la selección de variables que posteriormente haremos en la regresión del modelo que creemos.

### Year + Price

```{r analisis Year + Price, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Year, train$Price)) +
  geom_boxplot(aes(group=Year)) +
  geom_jitter(alpha=0.1) +
  geom_smooth(method="loess") +
  scale_y_log10()
```
```{r,message=FALSE, warning=FALSE}
data.frame(train$Year, train$Price) %>% chart.Correlation()
```

Se aprecia cierta correlación entre el año de fabricación del modelo y el precio del coche. Cuanto más nuevo es, más valor tiene. No influye de manera significativa y drástica año a año pero si aumenta, aunque sea en poca proporción, el valor del coche.

### Make + Price

```{r analisis Make + Price, message=FALSE, warning=FALSE}
grid.arrange(
  ggplot(train, aes(reorder(Make, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Make, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```
Lo que podemos ver es que hay mas marcas baratas que caras. Las marcas más caras son las de coches de lujo y hay muy pocos coches de este tipo en este dataset. 
Por otro lado, hay muchos coches de gama media de precio decente, como Hyundai y Maruti. Esto nos da una pista de que la marca de un coche puede determinar su precio.

Como hemos observado que muchas de las marcas de coche seguían una distribución parecida en cuanto al precio, se han agrupado en 3 gamas: gama baja, gama media y gama alta. Así, su visualización y la posterior utilidad de la marca en el modelo de regresión lineal será más frutífera y simplificada.

```{r analisis Gama + Price, message=FALSE, warning=FALSE}
grid.arrange(
  ggplot(train, aes(reorder(Gama, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Gama, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Los coches de gama media representan la mayoría de muestras en nuestro dataset. Después, los de gama alta y por último los que menos relevancia tienen en nuestros datos, de momento, son los de gama baja. Esta agrupación favorece tanto la representación de los datos de manera más ordenada como la visualización de los mismos. Además, no tendría sentido meter tantas marcas en un modelo de regresión lineal de manera unitaria. 


### Location + Price

```{r análisis Location+Price, message=FALSE, warning=FALSE}
ggplot(train, aes(Location, Price))+geom_boxplot(aes(group=Location))+geom_jitter(alpha=0.1)+geom_smooth(method="loess")+scale_y_log10()
grid.arrange(
  ggplot(train, aes(reorder(Location, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Location, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Los coches disponibles están bien distribuidos en cada una de las ciudades de la India y como se aprecia, no tiene mucha relación el lugar de venta con el precio que cuesta.

### Kilometers Driven + Price

```{r analisis Kilometers_Driven+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(log(Kilometers_Driven), log(Price)))+
  geom_boxplot(aes(group=Kilometers_Driven))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()
```
```{r,message=FALSE, warning=FALSE}
plot(log(train$Kilometers_Driven), log(train$Price))
```
```{r, message=FALSE, warning=FALSE}
data.frame(log(train$Kilometers_Driven), log(train$Price)) %>%
  chart.Correlation()
```

La empresa de ventas de coches parece haber decidido que no es relevante el número de kilómetros recorridos con respecto al precio. Mientras el coche circule y esté en óptimas condiciones, no se tiene en cuenta el número de kilómetros que suele estar relacionado con el año de fabricaión del coche.

### Fuel Type + Price

```{r análisis FuelType+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Fuel_Type, Price))+
  geom_boxplot(aes(group=Fuel_Type))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(Fuel_Type, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Fuel_Type, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Lo primero que se aprecia es que la mayoria de coches son de diésel y gasolina y además son los que mayor precio tienen. Un coche diésel es más caro que uno de gasolina generalmente básicamente por el consumo que realiza cada uno de ellos.

Pero, tiene relación el tipo de combustible con los kilómetros recorridos? 

### Fuel_Type + Kilometers_driven

```{r}
train %>% ggplot(aes(x=Fuel_Type, y=log(Kilometers_Driven), fill=Transmission)) +geom_boxplot()+ggtitle ("Km recorridos según el tipo de combustible por tipo de transmisión") +theme (plot.title = element_text(size=rel(1.25), vjust=2, face="bold", color="black")) 
```

```{r}
train %>% ggplot(aes(x=log(Kilometers_Driven), y=log(Price), fill=Fuel_Type)) +geom_boxplot()+ggtitle ("Precio según los km recorridos por tipo de combustible") +theme (plot.title = element_text(size=rel(1.25), vjust=2, face="bold", color="black")) 
```
Con esto podemos apreciar que los kilómetros que recorramos sí importa en qué tipo de coche lo hagamos puesto que no es lo mismo recorrer 100.000 km con un coche Diésel que con un coche de gasolina.  Un factor clave que a menudo hace caer la balanza del lado de los diésel es que la mayoría de compradores prefiere gastar más en la adquisición de un coche diésel,que como podemos ver en la gráfica, son más caros, que pagar más en los repostajes por haber comprado un gasolina. Es como si uno hiciera una inversión mayor al principio y luego ya fuese toda una vida útil del coche de ahorro.

### Transmission + Price

```{r análisis Transmission+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Transmission, Price))+
  geom_boxplot(aes(group=Transmission))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(Transmission, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Transmission, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

En este dataset hay más coches manuales que automáticos como se aprecia pero los automáticos son más caros. Esto es porque ofrecen mayor comodidad, la conducción es más segura y atenta al tráfico al no tener que estar pendiente del pedal y la palanca, aparte de la diferencia de consumo entre ambos.


```{r}
train %>% ggplot(aes(x=Fuel_Type, y=Price, fill=Transmission)) +geom_boxplot()+ggtitle ("Precio de los coches según el tipo de combustible por tipo de transmisión") +theme (plot.title = element_text(size=rel(1.25), vjust=2, face="bold", color="black"))
```
Una vez más, esto confirmó que el vehículo de gasolina es más barato que el diésel.

### Owner Type + Price

```{r análisis OwnerType + Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Owner_Type, Price))+geom_boxplot(aes(group=Owner_Type))+geom_jitter(alpha=0.1)+geom_smooth(method="loess")+scale_y_log10()
grid.arrange(
  ggplot(train, aes(reorder(Owner_Type, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Owner_Type, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

La mayoría de coches de segunda mano son los que han pasado ya por un conductor o en su defecto por dos. Antigüedad de 3 dueños es poco común y se da pocas veces generalmente. Está estrechamente relacionado el precio con los dueños que ha tenido el coche, siendo más caros los que menos dueños han tenido, lógicamente.

### Engine + Price

```{r análisis Engine+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Engine, log(Price)))+
  geom_boxplot(aes(group=Engine))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$Engine, log(train$Price)) %>% chart.Correlation()
```

Atendiendo a los gráficos se tiene una alta correlación entre la cilindrada del motor y el precio del coche. 
Cuanto mayor sea la cilindrada del motor, mayor será el precio del coche ya que es un factor determinante en la potencia del coche y en el combustible que éste consume.

### Power + Price

```{r análisis Power+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Power, train$Price))+
  geom_boxplot(aes(group=train$Power))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$Power, train$Price) %>% chart.Correlation()
```

La potencia del motor está relacionada altamente y de manera lineal con el precio del coche. A mayor potencia, mayor será el precio de compra. 

### Seats + Price

```{r  análisis Seats+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Seats, train$Price))+
  geom_boxplot(aes(group=train$Seats))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(train$Seats, train$Price, median), train$Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(train$Seats, train$Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Se aprecia una buena e igualada dstribución en el precio de los coches en función del número de asientos que posean. Los más caros son los biplaza debido, seguramente, a que las marcas de lujo como Lamborguini y Bently venden sobretodo deportivos biplaza. Es evidente que el número de plazas en el coche a igualdad de condiciones, afectará pero no parece altamente significativo en este dataset. También es cierto que coches biplaza sólo tenemos 11 en este dataset y es dificil sacar una conclusión con certeza.

### Kmpl/Kmpkg + Price

```{r análisis kmpl+Price, message=FALSE, warning=FALSE}
ggplot(train, aes(train$kmpl, train$Price))+
  geom_boxplot(aes(group=train$kmpl))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$kmpl, log(train$Price)) %>% chart.Correlation()
```


```{r análisis kmpkg+ Price, message=FALSE, warning=FALSE} 
ggplot(train, aes(log(train$kmpkg), log(train$Price)))+
  geom_boxplot(aes(group=train$kmpkg))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(log(train$kmpkg), log(train$Price)) %>% chart.Correlation()
```


La relación entre el kilometraje y el precio no va a ser diferencial ni significativa en nuestro análisis. 

En conclusión, las variables que más afectan a nuestra variable respuesta, el precio, son: la marca, el tipo de combustible, el tipo de transmision, la cilindrada y la potencia y en menor medida pero que también analizaremos: el año de fabricación, los dueños que ha tenido y el número de plazas que posee

### Engine + Power

```{r}
plot(train$Engine,train$Power)
train %>% select(Price, Engine, Power) %>% mutate(Price=log10(Price)) %>% cor() %>% ggcorrplot(lab=TRUE)
```

Existe una alta correlación entre las variables Engine y Power, al igual que en el mundo real, la cilindrada del motor determina la potencia de éste. Es por eso que después en el modelo nos valdrá con incluir solamente una de las dos. 

## {-}

# AJUSTE, INTERPRETACIÓN Y DIAGNOSIS DEL MODELO DE REGRESIÓN LINEAL MÚLTIPLE

```{r, message=FALSE, warning=FALSE}
cor(train[, c(3, 8, 9, 11)])
```


```{r, message=FALSE, warning=FALSE}
#Trabajos con las variables cuantitativas
reg.fit.selec=regsubsets(x=train[, c(3, 8, 9, 10)], y=train$Price)
reg.summary=summary(reg.fit.selec)
summary(reg.fit.selec)
```

Vamos a proceder a seleccionar las variables con las que vamos a hacer la regresión, empezamos con las variables cuantitativas unicamente.
El mejor modelo con una variable explicativa, sería el que contiene Power.
El mejor modelo con dos variables explicativas, sería el que contiene Year y Power
El mejor modelo con tres, el que contiene Year, Power y Engine
El mejor modelo con cuatro variables es el que contiene las cuatro.

**Estadisticos R²:**

```{r criterios, message=FALSE, warning=FALSE}
#Estadisticos R^2:
reg.summary$rsq
```

**Estadisticos R² ajustado:**

```{r, message=FALSE, warning=FALSE}
#Estadisticos R^2 ajustado:
reg.summary$adjr2
```

El mejor modelo es el que maximiza la R² y la R² ajustada. En este caso y teniendo en cuenta sólo 4 covariables, podríamos realizar un modelo con ellas pero siempre que se pueda simplificar y ello no reduzca los estadísticos en gran medida, puede ser práctico escoger el modelo con dos covariables.

```{r, message=FALSE, warning=FALSE, results='hide'}
par(mfrow=c(1,2))
plot(reg.summary$rss ,xlab="Numero de variables ",ylab="RSS",
     type="l") #aqui usamos rss
plot(reg.summary$adjr2 ,xlab="Numero de variables ",
     ylab="R2 ajustada",type="l")
num_var <- which.max(reg.summary$adjr2)
points(num_var,reg.summary$adjr2[num_var], col="red",cex=2,pch=20)
```

**CP**

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$cp
plot(reg.summary$cp ,xlab="Numero de variables ",ylab="Cp",type="l")
num_var <- which.min(reg.summary$cp)
points(num_var,reg.summary$cp[num_var], col="red",cex=2,pch=20)
``` 

**BIC**

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$bic
plot(reg.summary$bic ,xlab="Numero de variables ",ylab="Bic",type="l")
num_var <- which.min(reg.summary$bic)
points(num_var,reg.summary$bic[num_var], col="red",cex=2,pch=20)
```

El criterio de información de Akaike (AIC), el criterio de información de Akaike corregido (AICc) y el criterio de información bayesiano (BIC) son medidas de la calidad relativa de un modelo que representan el ajuste y el número de términos en el modelo.
Una vez utilizados los criterios y estadísticos para seleccionar las variables significativas, en este caso cuantitativas, y aunque los criterios no indiquen lo mismo, tomando la iniciativa y mirando los estadísticos, se ve conveniente escoger las variables Year y Power para explicar el modelo. Así, conseguimos que se simplifique y consideramos que se ajustan bien a los datos, además, falta aún añadir las variables cualitativas. 

Ahora vamos a realizar lo mismo pero añadiendo las variables que están como factor en nuestros datos.

```{r, message=FALSE, warning=FALSE}
x=model.matrix(~Year+Transmission+Owner_Type+Engine+Power+Seats+Gama,data=train)
reg.fit.select=regsubsets(x[,-1], y=train$Price) 
#Quitamos la intercptación que por defecto se construye en la matriz de diseño, ya que la funcion regsubsets tambien la incluye por defecto
reg.summary= summary(reg.fit.select)
reg.summary
```

Parece ser que los coches de gama baja y gama media serán importantes en la creación de un modelo explicativo de los datos. Al intentar incluir la variable Fuel_Type nos aparece redundancia pero es una variable con importante correlación y que consideraremos al crear el modelo de regresión. Una vez añadidas las variables factor, vamos a ver que variables seleccionamos.

```{r , message=FALSE, warning=FALSE}
reg.summary$adjr2 
plot(reg.summary$adjr2 ,xlab="Numero de variables ", ylab="R2 ajustada",type="l")
num_var <- which.max(reg.summary$adjr2)
points(num_var,reg.summary$adjr2[num_var], col="red",cex=2,pch=20)
```

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$cp
plot(reg.summary$cp ,xlab="Numero de variables ",ylab="Cp",type="l")
var <- which.min(reg.summary$cp)
points(var,reg.summary$cp[var], col="red",cex=2,pch=20)
```

```{r, message=FALSE, warning=FALSE}
reg.summary$bic
plot(reg.summary$bic ,xlab="Numero de variables ",ylab="Bic",type="l")
var <- which.min(reg.summary$bic)
points(var,reg.summary$bic[var], col="red",cex=2,pch=20)
```

Gracias a los métodos para saber cual es el mejor modelo y al summary se obtiene que el mejor modelo de regresión lineal multiple es es el que contiene: Year, Transmission manual, OwnerType second, Engine, Power, Seats, Gama baja y Gama media y con 6 covariables sería el modelo formado por: Year, Transmission manual, Power, Seats, Gama baja y gama media.  Teniendo en cuenta la variable Fuel_Type también, vamos a añadirla al modelo. Estos métodos tienen muy en cuenta el valor de la R adjusted pero nosotros lo evaluaremos por nosotros mismos y decidiremos cuánto de importante es el aumento de ese estadístico a la hora de aumentar variables en el modelo.

Para ajustar un modelo de regresión lineal múltiple mediante mínimos cuadrados, se utiliza la función lm(). Mediante esta función ajustamos una recta de regresión, con Price como variable respuesta.
Los posibles modelos que podemos utilizar para explicar nuestros datos,teniendo en cuenta el análisis anterior,son:

```{r}
mod0=lm(log10(Price) ~ Year+Power,data=train) #2 variables
mod1=lm(log10(Price) ~ Year+Fuel_Type+Power,data=train) #2 variables +fuel_type
mod2=lm(log10(Price) ~ Year+Power+Gama,data=train) #3variables
mod3=lm(log10(Price) ~ Year+Fuel_Type+Power+Gama,data=train) #3 variables +fuel
mod4=lm(log10(Price) ~ Year+Power+Seats+Gama,data=train) #4 variables
mod5=lm(log10(Price) ~ Year+Fuel_Type+Power+Seats+Gama,data=train) #4 var + fuel_type
mod6=lm(log10(Price) ~ Year+ Transmission+Power+Seats+Gama,data=train) #5 var
mod7=lm(log10(Price) ~ Year+Fuel_Type+Transmission+Power+Seats+Gama,data=train) #5 var + fuel
mod8=lm(log10(Price) ~ Year+Transmission+Owner_Type+Power+Seats+Gama,data=train) #6var
mod9=lm(log10(Price) ~ Year+Fuel_Type+Transmission+Owner_Type+Power+Seats+Gama,data=train) #6var + fuel
mod10=lm(log10(Price) ~ Year+Transmission+Owner_Type+Power+Engine+Seats+Gama,data=train) #7var
mod11=lm(log10(Price) ~ Year+Fuel_Type+Transmission+Owner_Type+Power+Engine+Seats+Gama,data=train) #7var+fuel 
```

Vamos a chequearlos para ver cual obtiene mejores estadísticos:

```{r, message=FALSE,warning=FALSE}

compare_performance(mod0,mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, rank=TRUE)
plot(compare_performance(mod0,mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, rank=TRUE))
```

Analizando cada uno de los modelos, sus índices y en qué medida afecta el aumento o disminución de variables, se decide que los mejores modelos hasta el momento son:

-El modelo nº 2 tiene como variables: Year, Power y Gama 

-El modelo nº 3 tiene como variables: Year, Fuel_Type, Power y Gama

-El modelo nº 6 tiene como variables: Year, Transmission, Power, Seats y Gama

-El modelo nº 7 tiene como variables: Year,Fuel_Type,Transmission,Power,Seats y Gama

-El modelo nº 11 tiene como variables: Year, Fuel_Type, Transmission, Owner_Type, Power, Engine, Seats y Gama

```{r}
compare_performance(mod2,mod3,mod6,mod7,mod11, rank=TRUE)
plot(compare_performance(mod2,mod3,mod6,mod7,mod11, rank=TRUE))
```

Se va a analizar primero el modelo con más variables, el **modelo 11**:

```{r}
summary(mod11)
```

Si observamos los p-valores de los test de hipótesis para los coeficientes individuales, observamos que para alguna variable no se puede rechazar que el coeficiente sea cero. Eliminamos por tanto la variable "Seats" de nuestro modelo 11. 

```{r}
mod11=lm(log10(Price) ~ Year+Fuel_Type+Transmission+Owner_Type+Power+Engine+Gama,data=train)
summary(mod11)
```

En algunos casos, para que la relación entre la variable respuesta y los regresores sea lineal, éstos requerirán de una transformación. Por ejemplo, observemos la relación entre la variable Price y Power:

```{r}
train %>% ggplot(aes(x= Power, y=Price)) + 
  geom_point()+
  geom_smooth()
```

Se puede observar, que claramente no existe una relación lineal entre ambas. Pero si aplicamos una transformación no lineal, la relación entre ambas log(Power) y log(Price) pasa a ser lineal aproximadamente.

```{r}
train %>% ggplot(aes(x= log(Power), y=log(Price))) + 
  geom_point()+
  geom_smooth()
```


```{r}
mod11=lm(log10(Price) ~ Year+Fuel_Type+Transmission+Owner_Type+log(Power)+Engine+Gama,data=train)  
summary(mod11)
```

Después de construir el modelo de regresión, con la variable transformada, se observa que el valor del coeficiente relacionado con la variable Power es mucho mayor. Además, el ajuste mejora pasando de un R²adj=0.891 a R²adj=0.897. Haciendo una diagnósis del modelo:

```{r}
check_model(mod11)
plot(mod11)
```

En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos es constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos siguen una distribución normal excepto en las colas que varía un poco. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook.

```{r}
dwtest(mod11, alternative = "two.sided")
vif(mod11)
```

Además, gracias al *Durbin Watson test* sabemos que no hay evidencias de autocorrelación.
Por otro lado, tenemos un problema de multicolinealidad cuando las variables explicativas (regresores) están relacionadas entre sí, de forma que solapan información para predecir la respuesta.
Cuando tenemos multicolinealidad, la estimacion de los coeficientes del modelo no es muy estable y por tanto los errores de estimación son grandes. Utilizamos el VIF para comprobarlo.
Los límites de referencia que se suelen emplear son:

  -VIF = 1: Ausencia total de colinealidad.
  
  -1 < VIF < 5: La regresión puede verse afectada por cierta colinealidad.
  
  -5 < VIF < 10: Causa de preocupación.
  
y vemos que no tenemos valores elevados, por tanto no hay problemas de multicolinealidad. También lo podemos comprobar gracias al gráfico ''Collinearity'' . Aunque entre los distintos tipos de gasolina si que exista cierta colinealidad, ello no afectará al modelo.
Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R2 adj de aproximadamente el 90%, realmente bueno ya para un modelo lineal. OLS son las distancias verticales entre las respuestas observadas en la muestra y las respuestas del modelo. Como conclusión a este modelo diríamos que se adecúa a los datos, pero veamos si reduciendo el número de variables, es decir, simplificando el problema, podemos mantener la buena explicatividad que necesitamos.


Se va a analizar ahora el siguiente modelo, el **modelo 7**:

```{r}
summary(mod7)
```

Si observamos los p-valores de los test de hipótesis para los coeficientes individuales, observamos que para alguna variable no se puede rechazar que el coeficiente sea cero. Eliminamos por tanto la variable "Seats" de nuestro modelo 7. Además, gracias al análisis de antes, podemos meter Power transformada como logaritmo para permitirle esa linealidad con el precio.

```{r}
mod7=lm(log10(Price) ~ Year+Fuel_Type+Transmission+log(Power)+Gama,data=train) 
summary(mod7)
```

Después de construir el modelo de regresión, con la variable transformada, se observa que el valor del coeficiente relacionado con la variable Power es mayor en 1 unidad. Además, el ajuste mejora considerablemente pasando de un R²adj=0.89 a R²adj=0.896. Haciendo una diagnósis del modelo:

```{r}
check_model(mod7)
plot(mod7)
```

En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos es constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos siguen una distribución normal excepto en las colas que varía un poco. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook.

```{r}
dwtest(mod7, alternative = "two.sided")
vif(mod7)
```

Además, gracias al *Durbin Watson test* sabemos que no hay evidencias de autocorrelación. 
Utilizamos el VIF y el gráfico de ''Collinearity'' para analizar la colinealidad de las variables y vemos que no tenemos valores elevados, excepto entre los diferentes tipos de fuente de gasolina entre ellos, por tanto no hay problemas de multicolinealidad.

Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R ajustado de aproximadamente el 90%. Realmente bueno ya para un modelo lineal. 

Se va a analizar ahora el siguiente modelo, el **modelo 6**:

```{r}
summary(mod6)
```

Gracias al análisis de antes, podemos meter Power transformada como logaritmo para permitirle esa linealidad con el precio.

```{r}
mod6=lm(log10(Price) ~ Year+ Transmission+log(Power)+Seats+Gama,data=train)
summary(mod6)
```

Al transformar Power para lograr linealidad, se aprecia que la variable Seats deja de ser significativa por lo que procedemos a eliminarla:

```{r}
mod6=lm(log10(Price) ~ Year+ Transmission+log(Power)+Gama,data=train)
summary(mod6)
```

Después de construir el modelo de regresión, con la variable transformada, se observa que el valor del coeficiente relacionado con la variable Power es mayor en 1 unidad. Además, el ajuste mejora considerablemente pasando de un R²adj=0.874 a R²adj=0.885. Haciendo una diagnósis del modelo:

```{r}
check_model(mod6)
plot(mod6)
```

En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos es constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos siguen una distribución normal excepto en las colas que varía un poco. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook.

```{r}
dwtest(mod6, alternative = "two.sided")
vif(mod6)
```

Además, gracias al *Durbin Watson test* sabemos que no hay evidencias de autocorrelación. 
Utilizamos el VIF y el gráfico de la colinealidad para comprobar ello y vemos que no tenemos valores elevados, excepto entre los diferentes tipos de fuente de gasolina entre ellos, por tanto no hay problemas de multicolinealidad.

Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R cuadrado de aproximadamente el 90%. Realmente bueno ya para un modelo lineal. 

Se va a analizar ahora el siguiente modelo, el **modelo 3**:

```{r}
summary(mod3)
```

Si observamos los p-valores de los test de hipótesis para los coeficientes individuales, observamos que para alguna variable no se puede rechazar que el coeficiente sea cero. Además, gracias al análisis de antes, podemos meter Power transformada como logaritmo para permitirle esa linealidad con el precio.

```{r}
mod3=lm(log10(Price) ~ Year+Fuel_Type+log(Power)+Gama,data=train)
summary(mod3)
```

Después de construir el modelo de regresión, con la variable transformada, se observa que el valor del coeficiente relacionado con la variable Power es mayor en 1 unidad. Haciendo una diagnósis del modelo:

```{r}
check_model(mod3)
plot(mod3)
```

En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos es constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos siguen una distribución normal excepto en las colas que varía un poco. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook

```{r}
dwtest(mod3, alternative = "two.sided")
vif(mod3)
```

Además, gracias al *Durbin Watson test* sabemos que no hay evidencias de autocorrelación. 
Utilizamos el VIF para comprobar la multicolinealidad y vemos que no tenemos valores elevados, por tanto no hay problemas de multicolinealidad.

Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R cuadrado de aproximadamente el 90%. Realmente bueno ya para un modelo lineal.

Se va a analizar ahora el siguiente modelo, el **modelo 2**:

```{r}
summary(mod2)
```

Gracias al análisis de antes, podemos meter Power transformada como logaritmo para permitirle esa linealidad con el precio.

```{r}
mod2=lm(log10(Price) ~ Year+log(Power)+Gama,data=train)
summary(mod2)
```

Después de construir el modelo de regresión, con la variable transformada, se observa que el valor del coeficiente relacionado con la variable Power es mayor en 1 unidad. Además, el ajuste mejora considerablemente pasando de un R²adj=0.866 a R²adj=0.877. Haciendo una diagnósis del modelo:

```{r}
check_model(mod2)
plot(mod2)
```

En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos es constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos siguen una distribución normal excepto en las colas que varía un poco. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook.

```{r}
dwtest(mod2, alternative = "two.sided")
vif(mod2)
ols_coll_diag(mod2)
```

Además, gracias al *Durbin Watson test* sabemos que no hay evidencias de autocorrelación. 
Utilizamos el VIF para comprobar la colinealidad y vemos que no tenemos valores elevados, por tanto no hay problemas de multicolinealidad.

Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R cuadrado de aproximadamente el 90%. Realmente bueno ya para un modelo lineal.

De nuestro análisis hemos obtenido información:

-El año de fabricación del coche y la gama en función de la marca dan una indicación visual y un efecto significativo en el precio.

-La potencia se correlaciona mejor con el precio que con el motor.

-Además de estas variables, no se muestra ninguna indicación clara en las demás.

Se decide que **el mejor modelo para explicar nuestros datos es este, el modelo 2**. Vamos a analizar algunos parámetros más que serán importantes y, aunque se trata de un modelo bueno, tiene defectos que se solucionarían haciendo que el modelo deje de ser lineal. 

Ahora, trataremos los valores ajustados y los reales de nuestros datos.Los valores ajustados (o predichos) son los valores de y que esperaría para los valores de x dados de acuerdo con el modelo de regresión construido (o visualmente, la línea de regresión recta de mejor ajuste).

```{r}
train$Price.mod2 <- mod2$fitted.values
plot(x = log(train$Price),                     # True values on x-axis
     y = mod2$fitted.values,               # fitted values on y-axis
     xlab = "True Values",
     ylab = "Model Fitted Values",
     main = "Regression fits")
```

En el diagrama de dispersión ilustrado, se puede ver que no todos los puntos de datos caen exactamente en la línea de regresión estimada. Esto significa que, para un determinado coche, los valores del precio pueden ser diferentes de los valores de precio previstos. La diferencia se llama errores residuales. Se ve sobretodo una dispersión en los coches de precio más bajo.

A continuación vamos a estudiar los residuos del modelo. El estudio de residuos es una herramienta formidable en el estudio de las regresiones lineales. Nos sirve para saber si se están cumpliendo las premisas de linealidad de las relaciones, homocedasticidad y normalidad de los residuos. Para una mejor visualización de los residuos del modelo, veamos los siguientes gráficos:

```{r}
ols_plot_diagnostics(mod2)
```

En cuanto a la normalidad de los residuos, en el histograma se ve un aspecto general normal. Por supuesto no reproduce exactamente la curva normal,pero podemos atribuir esas desviaciones. Además, como dijimos anteriormente, en el Q-Q Plot se ajusta bien a la recta excepto en los extremos. 

```{r}
residuos=resid(mod2)
ks.test(residuos, 'pnorm')
```

Se contrasta la hipótesis nula de que los residuos del modelo se distribuyen según una distribución Normal. Al obtener un p.valor menor que 0.05 rechazamos H0 y por consiguiente se tiene que los residuos no siguen una distribución Normal. Sin embargo, debido a que los modelos lineales en general son robustos, proseguiremos con el análisis asumiendo cierta normalidad. 
Obtenemos:

-Valores ajustados: valores ajustados (valores de la variable respuesta) para las observaciones originales de la predictora.
    
-Residuos: diferencia entre valor observado de la respuesta y valor ajustado por el modelo.
    
-Estadísticos: residuos estudentizados del modelo ajustado.

Ahora, vamos a analizar si existen observaciones influyentes y/o anómalas:

```{r}
stud.del.resids=rstudent(mod2)
range(stud.del.resids) #rango por defecto 
n=length(train$Price)
alpha=0.005
valorcritico= qt(1-alpha/(2*n),df=n-3-1) #recordamos que p=k+1 es decir el numero de covariables+1
ols_plot_resid_stud_fit(mod2) 
```

Encontramos multitud de outliers pero la mayoría cercanos a los valores normales. Hay puntos , en concreto 6 de ellos que se alejan bastante de esa normalidad y hacen que el rango de los residuos sea más amplio. 

En cuanto a los puntos leva o leverage:

El comando `hatvalues´ nos sirve para obtener directamente los valores $h_{ii}$ o también llamados valores **leverage** o valores **leva**.

```{r}
plot(hatvalues(mod2))
valorLimite = 2*3/n
valorLimite
```
Algunos valores superan el umbral pero la mayoría de las observaciones están concentradas dentro del umbral permitido, por lo que aquí también aparecen varios coches como outliers.

En cuanto a los DFFITS, para el gráfico donde evaluamos si los DFFITS son grandes o pequeños mejor usar como umbrales los valores -1, 1, tal y como comentamos en teoría, cuando analicemos tamaños moderados de data sets. En el caso de analizar grandes bases de datos, **Big data**, está bien la cota que definen por defecto en el gráfico, que usa la formula 2sqrt(p/n). Representan el numero de desviaciones estándar que cambia la predicción de la i-ésima respuesta cuando dicha observación es excluida del ajuste.

```{r}
#dffits(mod2)
ols_plot_dffits(mod2)
```

Como en los dos gráficos anteriores cuando analizamos los puntos leverage, aquí también nos aparecen las mismas muestras alejadas de esa media, consideraremos todos esos puntos que están fuera del umbral como observaciones anómalas.

Para ver la linealidad que sigue cada una de las variables regresoras con la variable respuesta, otro gráfico que lo verifica es: 

```{r}
avPlots(mod2)
```

Para analizar más profundamente la variabilidad explicada por el modelo:

```{r}
summary(mod2)
anova(mod2)
```
La variabilidad del modelo se puede descomponer como SST = SSM + SSR. SST es la variación total. SSM es la variación explicada por el modelo. SSR es la variación no explicada por el modelo. Para nuestros datos tenemos: SSM de 163.87,393.63 y 29.58, con SSR 82.03. Por lo tanto, la variabilidad explicada por el modelo de regresión es mayor que la que queda sin explicar (residuos).

Un estadístico F mayor de 1 indica un buen ajuste del modelo. El estadístico F contrasta si el modelo tiene significativa capacidad predictiva. En el contraste la hipotesis nula es F = 1, con un p-valor menor de 0.05 (2.2e-16) se rechaza la hipótesis nula. Por lo tanto concluimos que el modelo tiene una capacidad predictiva significativa.

# PREDICCIÓN SOBRE LOS DATOS DE TESTING. EVALUACIÓN DEL MODELO

Lo primero que tenemos que realizar es la transformación de la variable Make, la cual dividimos en subgrupos. Además, eliminamos las dos columnas que nos eran inútiles del dataset.

```{r}
str_split(test$Name, " ", simplify=TRUE) %>% subset(select=1) %>% unique() -> car_makes
car_makes[car_makes=="Land"] <- "Land Rover" #Anomalía en los datos
car_makes_regex <- paste(car_makes, collapse="|")
str_extract(test$Name, car_makes_regex) -> make
test %>% mutate(Make = str_to_title(make)) -> test
```


```{r}
test %>% 
  mutate(
    Gama = case_when( 
      test$Make=="Datsun" |test$Make=="Smart" |test$Make=="Tata" |test$Make=="Fiat" |test$Make=="Chevrolet" |test$Make=="Ambassador" ~ "Gama baja",
      test$Make=="Skoda"|test$Make=="Renault" |test$Make=="Ford" |test$Make=="Honda"|test$Make=="Volkswagen" |test$Make=="Hyundai" |test$Make=="Nissan" |test$Make=="Maruti" ~ "Gama media",
      test$Make=="Bentley"|test$Make=="Porsche" |test$Make=="Land Rover" |test$Make=="Jaguar" |test$Make=="Mini" |test$Make=="Mercedes-Benz" |test$Make=="Audi" |test$Make=="Bmw" |test$Make=="Jeep" |test$Make=="Volvo" |test$Make=="Isuzu" |test$Make=="Mitsubishi" |test$Make=="Toyota" |test$Make=="Force" |test$Make=="Mahindra"~ "Gama alta"
    )
  ) -> test

test$Gama <- as.factor(test$Gama)

```


```{r}
test %>% select(-New_Price) -> test
test %>% select(-X) -> test
```

Y para finalizar, veamos cómo predice el modelo:

```{r}
pred=predict(mod2,test[,-12])
tables=as.data.frame(cbind(Prediccion=exp(pred),Observ=log(test[,12]), Dif=exp(pred)-log(test[,12])))
summary(tables)
```
 Debido a que tenemos un error pequeño de predicción podemos considerar que tenemos un buen modelo.
 
```{r}
plot(exp(pred),log(test$Price),col="blue", xlab = "Precio según el modelo",
     ylab = "Precio observado", main="Representación del precio predicho frente al observado")
```

#Análisis de componentes principales

El análisis de componentes principales (en inglés, PCA) es una técnica utilizada para describir un conjunto de datos en términos de nuevas variables denominadas componentes no correlacionadas. Estas nuevas componentes se construyen a partir de las variables existentes, eso sí, debemos asegurarnos de que las variables utilizadas en PCA sean variables cuantitativas (no podemos usar variables cualitativas ni categóricas). Con esta técnica se pretende reducir la dimensionalidad del problema en cuestión.

```{r}
str(train)
train
corrplot(cor(train[, c(3,4, 8, 9, 14, 15)]), method = "ellipse") 
corPlot(train[, c(3,4, 8, 9, 14, 15)], cex = 1.2, main = "Matriz de correlación")
corrplot(cor(train[, c(3,4, 8, 9, 14, 15)]),method = "circle",       order = "hclust",         hclust.method = "ward.D",
         addrect =2,rect.col = 3,rect.lwd = 3)  
```
```{r}
cortest(cor(train[, c(3,4, 8, 9, 14, 15)]))
```
Tenemos evidencias para decir que las correlaciones son distintas de 0


```{r}
pca1 <- prcomp(train[, c(3,4, 8, 9, 14, 15)])
```

```{r}
plot(pca1)
```
```{r}
summary(pca1)
```
En nuestro conjunto de datos inicial, todas nuestras variables eran cuantitativas (menos la variable respuesta, que no utilizamos en aprendizaje no supervisado), sin embargo, las variables categorizadas que hemos creado no lo son. Así que haremos el análisis de componentes principales escalando las variables: Kilometers_Driven, Power, Seats, kmpl y kmpg.

```{r}
pca2 <- prcomp(train[, c(3,4, 8, 9, 14, 15)], scale=T)

pca2

```
Aquí arriba, podemos ver los diferentes pesos que otorga el análisis de componentes principales a cada una de las variables iniciales escaladas. Por ejemplo: en la primera componente principal (PC1), vemos que sobre todo se enfrentan las variables Engine y Power contra kmpl; en la segunda componente principal (PC2), vemos que se enfrenta la variable kmpg contra kmpl, Power,Year y Engine; en la tercera componente principal (PC3) se enfrentan los kilómetros que lleva recorridos el coche contra el año de fabricación y la variable kmpkg.

```{r}
summary(pca2)
```
La inercia de las primeras dimensiones muestra si existen relaciones fuertes entre las variables y sugiere el número de dimensiones que se deben estudiar.

Las dos primeras dimensiones de análisis expresan el 59,83% de la inercia total del conjunto de datos; eso quiere decir que el 59.83% de los individuos (o variables) nublan la variabilidad total es explicada por el plano. Este porcentaje es relativamente alto y, por lo tanto, el primer plano representa bien la variabilidad de los datos. Este valor es muy superior al valor de referencia que equivale al 34,95%, por lo que la variabilidad explicada por este plano es muy significativa (el valor de referencia es el cuantil 0,95 de la distribución de porcentajes de inercia obtenida simulando 1689 tablas de datos de tamaño equivalente sobre la base de una distribución normal).

A partir de estas observaciones, conviene interpretar también las dimensiones mayores o iguales a la tercera.

Sin embargo, aquí resulta difícil ver algo claro e intuitivo, así que haremos un pequeño resumen y un gráfico multivariante para mostrar la información más relevante del PCA.

Estudio del Plano 1:2

```{r}
PC1= pca2[[2]][,1]
PC2= pca2[[2]][,2]
PC3= pca2[[2]][,3]
PC4= pca2[[2]][,4]

componentes_princ <- cbind(PC1,PC2,PC3,PC4)
componentes_princ
library(ade4)
```

```{r}
plot(pca2)
biplot(pca2)
s.corcircle(componentes_princ[,-3], sub="PC1 Y PC2")

```

En el gráfico enfrentamos la primera y la segunda componente principal, y vemos como influyen cada una de las variables en los coches. Por ejemplo, el coche 1712, debe tener unos valores muy altos de Power y Engine que son las variables que "más tiran hacia la derecha", y el teorema 745, según el `biplot` debe tener un valor muy alto de kilometers_driven, que es la variable que "más tira en esa dirección". Si recordamos lo analizado previamente, en la sección del análisis exploratorio de datos, este teorema ya destacó por tener valores un tanto diferentes a los del resto por su desmesurado valor de kilómetros recorridos. Comprobamos que la información que nos proporciona el gráfico es totalmente coherente con lo que obtuvimos en el *EDA*.

La dimensión 1 opone individuos caracterizados por una coordenada fuertemente positiva en el eje (a la derecha del gráfico) a individuos caracterizados por una coordenada fuertemente negativa en el eje (a la izquierda del gráfico).

El grupo 1 (caracterizado por una coordenada positiva en el eje) comparte:
  -valores altos para la variable kmpkg.
  -valores bajos para las variables kmpl, Potencia y Motor (las variables se ordenan de la más débil).

El grupo 2 (caracterizado por una coordenada positiva en el eje) comparte:
  -valores altos para las variables Motor, Potencia y Kilómetros_Recorridos (las variables se ordenan de la más fuerte).
  -valores bajos para las variables kmpl, Year y kmpkg (las variables se ordenan de la más débil).

El grupo 3 (caracterizado por una coordenada negativa en el eje) comparte:
  -valores altos para las variables kmpl y Año (las variables se ordenan de la más fuerte).
  -valores bajos para las variables Motor, Potencia, Kilómetros_Conducidos y kmpkg (las variables se ordenan de menor a mayor).

La dimensión 2 opone individuos caracterizados por una coordenada fuertemente positiva en el eje (en la parte superior del gráfico) a individuos caracterizados por una coordenada fuertemente negativa en el eje (en la parte inferior del gráfico).

El grupo 1 (caracterizado por una coordenada positiva en el eje) comparte:
  -valores altos para las variables kmpl y Año (las variables se ordenan de la más fuerte).
  -valores bajos para las variables Motor, Potencia, Kilómetros_Conducidos y kmpkg (las variables se ordenan de menor a mayor).

El grupo 2 (caracterizado por una coordenada positiva en el eje) comparte:
  -valores altos para las variables Motor, Potencia y Kilómetros_Recorridos (las variables se ordenan de la más fuerte).
  -valores bajos para las variables kmpl, Year y kmpkg (las variables se ordenan de la más débil).

El grupo 3 (caracterizado por una coordenada negativa en el eje) comparte:
  -valores altos para la variable kmpkg.
  -valores bajos para las variables kmpl, Potencia y Motor (las variables se ordenan de la más débil).



```{r}
library(factoextra)

fviz_pca_var(pca2,axes = c(1,2), col.var = "cos2", alpha.var = "contrib" ) + theme_grey()
fviz_pca_var(pca2,axes = c(1,3), col.var = "cos2", alpha.var = "contrib" ) + theme_grey()

```

La suma de cos2 de una variable determinada sobre cada factor es 1. Esto significa que cada vector debería estar tocando el perímetro de la circunferencia unidad, pero no lo está haciendo ninguna prácticamente, ¿por qué?. Si observamos por ejemplo la variable Engine(al igual que Power), vemos que está muy cerca de tocar dicho perímetro, su proyección sobre las dimensiones 1 y 2 (componentes) indica su contribución a éstas, pero aún le falta algo de contribución que debe estar repartida por otra u otras dimensiones. Si está variable solo tuviese peso sobre las dos primeras dimensiones estaría tocando la circunferencia.

Podemos colorear las observaciones según alguna variable. Además podemos hacer que las variables que más contribuyen en este plano factorial, se resalten más que las que menos influencia tienen. También tenemos la posibilidad de dibujar elipses alrededor de cada grupo con un cierto nivel de confianza.

Como se aprecia en los gráficos anteriores, no tiene mucho sentido representar la segunda componente principal ya que no realiza un correcto enfrentamiento de variables y no nos aporta nada.




```{r}
#fviz_pca_ind(pca2,axes=c(1,2), col.ind = train$Gama, alpha.ind = "contrib" ) + theme_grey()
#fviz_pca_ind( pca2,axes=c(1,2),  habillage = as.factor( train$Gama ), addEllipses = TRUE, ellipse.level = 0.99 )
#fviz_pca_ind( pca2, axes=c(1,2),col.ind = train$Make, alpha.ind = "contrib" ) + theme_grey()
#fviz_pca_ind( pca2, axes=c(1,2),col.ind = train$Fuel_Type, alpha.ind = "contrib" ) + theme_grey()
#fviz_pca_ind( pca2, axes=c(1,2),habillage = as.factor( train$Fuel_Type ), addEllipses = TRUE, ellipse.level = 0.99 )
#fviz_pca_ind( pca2, axes=c(1,2),col.ind = train$Transmission, alpha.ind = "contrib" ) + theme_grey()
#fviz_pca_ind( pca2, axes=c(1,2),habillage = as.factor( train$Transmission ), addEllipses = TRUE, ellipse.level = 0.99 )
#fviz_pca_ind( pca2,axes=c(1,2), col.ind = train$Location, alpha.ind = "contrib" ) + theme_grey()
#fviz_pca_biplot( pca2, axes=c(1,2),col.ind = train$Gama )
```

```{r}
summary(pca2)
```

Por otro lado, podemos decir que lo que más nos interesa de este resumen es la proporción de la varianza total que consigue explicar cada componente principal. Según el resumen que acabamos de mostrar arriba, vemos que la varianza total explicada no aumenta mucho a partir de la tercera o cuarta componente principal (y que con todas las componentes principales, evidentemente, la varianza explicada es el 100%). Para visualizar esto haremos un gráfico de barras:

```{r}
screeplot(pca2, xlab="PCs")
```

Una estimación del número correcto de ejes a interpretar sugiere restringir el análisis a la descripción de los 3 primeros ejes. Estos ejes presentan una inercia superior a las obtenidas por el cuantil 0,95 de las distribuciones aleatorias (78,56% frente a 51,79%). Esta observación sugiere que solo estos ejes llevan una información real. En consecuencia, la descripción se situará en estos ejes.

```{r}
library(psych)
scree(train[, c(3,4, 8, 9, 14, 15)],main ="Grafico_de_Sedimentacion")
```

El grafico de Sedimentacion nos muestra la cantidad óptima de componentes a tomar en el análisis, siendo los valores por encima de la linea de 1.0 los más aceptables.

```{r}
fa.parallel(train[, c(3,4, 8, 9, 14, 15)],fa="pc")
```
Según los resultados del Análisis paralelo, el número de componentes deberá ser 3. 

Se comprueba que con PCA no se consigue lo que se busca, ni PC2 ni PC3 nos sirven para realizar una correcta redimensión de los datos. Nos damos cuenta de que nuestro problema es bastante difícil de resolver, dado que es complicado ver algún tipo de separación o tendencia de los coches en función de las variables categóricas o incluso en cuanto al precio. Aún así, si nos fijamos, en los gráficos que enfrentan PC1 con PC2, PC1 con PC3 y PC2 con PC3, parece que los coches de gama media y gama alta están más dispersos que los de gama baja.

```{r}
#library(FactoMineR)
#library(FactoInvestigate)
#res = PCA(train[, c(3,4, 8, 9, 14, 15)], graph=FALSE)
#Investigate(res) 
```


```{r}

```


