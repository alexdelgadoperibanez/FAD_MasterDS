---
title: "Análisis de Datos: Precio de los coches en la India"
author: "Amanda del Álamo & Alejandro Delgado"
date: "16/11/2021"
output:
  html_document:
    theme: paper
    highlight: zenburn
    code_folding: "hide"
    toc: yes
    toc_float: yes
    toc_depth: 1
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, include = FALSE}
library(dplyr)
# install.packages("readr")
library(readr)
# install.packages("mice")
library(mice)
#install.packages("stringr")
library(stringr)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
library(gridExtra)
library(gmodels)
#install.packages("Hmisc")
library(Hmisc)
#install.packages("ggthemes")
library(ggthemes)
#install.packages("ellipse")
library(ellipse)
library(corrplot)
library(ggcorrplot)
#install.packages("corrplot")
library(corrplot)
library(leaps)
#install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
library(GGally)
#install.packages("psych")
library(psych)
library("car")
```

# DATASET

```{r Carga de datos, message=FALSE, warning=FALSE}
data <- read.csv("cochesdataP.csv", na = c("","NA","NULL",NULL,"  ","/n" ))
head(data)
```

# DEFINICIÓN DE OBJETIVOS

Este dataset contiene toda la información acerca de un comercio de venta de coches usados en la India. Nuestro objetivo es predecir, a través de las características de un coche, cuanto nos costaría comprarlo.

# ANÁLISIS EXPLORATORIO INICIAL

La función glimpse() del paquete dplyr puede utilizarse para ver las columnas del conjunto de datos y mostrar alguna porción de ellos con respecto a cada atributo que pueda caber en una sola línea.

```{r Tipos de variables,  message=FALSE, warning=FALSE}
glimpse(data)
```

Con esta forma de visualización podemos observar mejor la naturaleza de los datos. Tenemos 6019 observaciones y 14 columnas y a simple vista vemos que muchos datos están bien tipados pero otros habrá que transformarlos, como puede ser el caso de la variable Mileage (Kilometraje) que está como Character ya que viene el número con su unidad de medida y habrá que decidir si ponerlo todo como km/kg o kmpl. Lo mismo nos pasa con Power (potencia) y New Price que parece tener muchos elementos faltantes. La variable Seats (asientos) es un double cuando debería ser entera... Hay muchas cosas que modificar para dar valor a estos datos.

1. Name: Nombre de las marcas y modelos de los coches.
2. Location: La ubicación en la que se vende el coche o está disponible para su compra.
3. Year: El año del modelo de coche.
4. Kilometers_Driven: El total de kilómetros recorridos en el coche por el anterior propietario en Km
5. Fuel_Type: El tipo de combustible utilizado por el coche.
6. Transmission: El tipo de transmisión utilizado por el coche.
7. Owner_Type: Indica si el coche es de primera, segunda, tercera, cuarta... mano.
8. Mileage: El kilometraje estándar ofrecido por la compañía de automóviles en kmpl o km/kg.
9. Engine: La cilindrada del motor en cc.
10. Power: La potencia máxima del motor en bhp (CV).
11. Seats: Número de asientos.
12. New_Price: El precio del coche, nuevo.
13. Price: El precio del coche usado en INR Lakhs (Rupias).


Con la función anterior hemos podido apreciar que hay datos que contienen diferentes tipos de unidades. Vamos a ver cuales son y como se dividen antes de limpiar los datos para luego saber como podemos tratarlas.

## Relación entre unidades {.tabset .tabset-fade .tabset-pills}

### Mileage

```{r , message=FALSE, warning=FALSE}
data %>% pull(Mileage) %>% 
  str_split(" ", simplify=TRUE) %>% 
  cbind(data$Fuel_Type) %>% 
  subset(select=2:3) %>% 
  as.data.frame() %>% table() #Extraigo los diferentes tipos que hay y como se relacionan
```

### Engine

```{r , message=FALSE, warning=FALSE}
data %>% pull(Engine) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table() # hago lo mismo para confirmar que solo hay un tipo
```

### Power

```{r , message=FALSE, warning=FALSE}
data %>% pull(Power) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table() # hago lo mismo para confirmar que solo hay un tipo
```

### New Price

```{r , message=FALSE, warning=FALSE}
data %>% pull(New_Price) %>% 
  str_split(" ", simplify=TRUE) %>% 
  subset(select=2) %>% table()
```

## {-}

Podemos observar que en Mileage y New_Price tenemos diferentes tipos de unidades.
Las diferentes unidades en Mileage tienen que ver con el tipo de combustible y las de New_Price se dividen en Rupias (Lakh) y Colón (Cr)
Más adelante dividiremos en dos variables distintas.

```{r Modificación de datos, results = TRUE, message=FALSE, warning=FALSE}
data %>% mutate(Mileage = as.numeric(str_extract(Mileage, "^[:graph:]+"))) -> data
data %>% mutate(Engine = as.numeric(str_extract(Engine, "^[:graph:]+"))) -> data
data %>% mutate(Power = as.numeric(str_extract(Power, "^[:graph:]+"))) -> data
data %>%
  mutate(Seats = as.integer(Seats)) -> data
data %>%
  mutate(Fuel_Type = as.factor(Fuel_Type)) %>%
  mutate(Transmission = as.factor(Transmission)) %>%
  mutate(Location = as.factor(Location)) %>%
  mutate(New_Price = as.numeric(str_extract(New_Price, "^[:graph:]+"))) -> data
data %>% mutate(Owner_Type = factor(Owner_Type, levels=c("First", "Second", "Third", "Fourth & Above"))) -> data
```

Hemos cambiado el tipo de variable de algunas de las columnas ya que no era el adecuado. A la variable Power se le introducen NA's por coerción debido a que tiene algun valor recogido como NA.
También hemos modificado la grafía del dato ya que venían con las unidades en el registro.


## Análisis variable "Year" {.tabset .tabset-fade .tabset-pills}

### Histograma

```{r , message=FALSE, warning=FALSE}
hist(data$Year)
```

### Boxplot

```{r , message=FALSE, warning=FALSE}
boxplot(data$Year, horizontal = TRUE)
```


### Histograma + Densidad

```{r, , message=FALSE, warning=FALSE}
ggplot(data, aes(x=Year)) + 
  geom_histogram(breaks=seq(1996,2020,by=1),aes(y=..density..), binwidth = 0.4,  fill="blue", colour="black") +
  geom_density(colour="green", fill="green",alpha=0.3)
```

## {-}

La primera variable que vamos a analizar es "Year", hace referencia al año en que se fabricó cada coche. 
Se trata de una variable cuantitativa, ya que podemos calcular la diferencia entre fechas, en la que aparecen los años desde 1996 hasta 2018.
Obtenemos que en el año 1998 se contabilizan 10 coches, en el año 2000, 23, en el 2004, 135. 
Va aumentando el número de coches progresivamente con el paso de los años hasta llegar a 2016 donde vuelve a disminuir también progresivamente. Esta variable está definida como "integer" y así la trataremos, ya que no nos da problema y nos aporta toda la información necesaria. 
Además, gracias al boxplot se aprecia que el 50% de los datos se encontrarán entre 2011 y 2017.

## Análisis variable "Kilometers_driven" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Kilometers_driven , message=FALSE, warning=FALSE}
summary(data$Kilometers_Driven)
```

### Histograma + Densidad

```{r , message=FALSE, warning=FALSE}
data %>% ggplot(aes(x=Kilometers_Driven)) +
  ggtitle("Kilómetros recorridos") +
  theme_fivethirtyeight() +
  geom_histogram(aes(y=..density..), color="white", fill="dark blue", bins = 50) + 
  geom_density() +
  scale_x_log10()
```

## {-}

La segunda variable a analizar es "Kilometers_driven", que hace referencia a los kilometros que lleva recorridos el coche. Se trata de una variable cuantitativa expresada como integer en nuestros datos. El mínimo de kilometros recorridos por un coche de los que estamos estudiando es de 171 mientras que el máximo llega hasta 6500.000. Analizándolo al detalle se aprecia que el valor máximo es un outlier ya que está muy lejos de la media y es el único coche con tantos km recorridos. Más adelante, decidiremos que hacer con ese valor, de momento, obtenemos que la media de kilometros recorridos por los coches es de 58738 y que el 50% de los datos se encuentran entre 53000 y 73000. Además hemos aplicado escala logarítmica en el histograma para una mejor visualización

## Análisis variable "Fuel_Type" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Fuel_Type , message=FALSE, warning=FALSE}
summary(data$Fuel_Type)
```

### Histograma

```{r , message=FALSE, warning=FALSE}
ggplot(data, aes(x=Fuel_Type)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black", ) 
```

## {-}

La tercera variable que vamos a analizar es "Fuel_Type", que hace referencia al tipo de combustible que usa cada coche. Se trata de una variable cualitativa. Está representada en nuestros datos como factor y los valores que  toma son CNG,LPG, Electric, Diesel y Pretol. Vamos a describir cada uno de los valores que toma esta variable:
    -CNG: El gas natural comprimido, más conocido por la sigla GNC, es un combustible para uso vehicular que, por ser económico y ambientalmente más limpio, es considerado una alternativa sustentable para la sustitución de combustibles líquidos.
    -LPG: El gas licuado del petróleo es la mezcla de gases licuados presentes en el gas natural o disueltos en el petróleo. Lleva consigo procesos físicos y químicos por ejemplo el uso de metano.
    -Diésel: El diésel o dísel, también denominado gasóleo o gasoil, es un hidrocarburo líquido de densidad sobre 850 kg/m³, compuesto fundamentalmente por parafinas y utilizado principalmente como combustible en calefacción y en motores diésel. Su poder calorífico inferior es de 35,86 MJ/l.
    -Petrol: La gasolina es formada con el petróleo refinado, utilizado principalmente como combustible, es esencial para la red mundial de transporte, el combustible primario que hace funcionar los motores de combustión interna que mueven la mayoría de los automóviles y otros sistemas de transporte.
    
De Electric, eléctricos es del tipo que menos muestras poseemos, sólo 2. De LPG y CNG también poseemos pocas (1 y  56 restivamente) y es en Diesel y Petrol donde tenemos la mayoría de los datos, siendo 3852 y 3325 las muestras respectivamente. 
Se muestra el histograma para visualizar la gran diferencia de muestras entre Diesel y Petróleo y las demás.


## {-}

## Análisis variable "Location" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Location , message=FALSE, warning=FALSE}
summary(data$Location) 
```

### Histograma

```{r , message=FALSE, warning=FALSE}
ggplot(data, aes(x=Location)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black")
```

## {-}

Otra de las variables es Location, que es la localización en que está disponible el coche para vender. Se trata de una variable cuantitativa que catalogamos como factor para estudiarla en función de las muestras que posea cada ciudad. La que menos coches disponibles tiene por el momento es Ahmedabad con 224 y le secunda Bangalore con 358 y por el otro extremo, tenemos a la ciudad de Hyderabad con 742 y Mumbai con el máximo de coches disponibles, 790. 

## Análisis variable "Transmission" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Transmission, message=FALSE, warning=FALSE}
summary(data$Transmission)
```

### Histograma

```{r, message=FALSE, warning=FALSE}
ggplot(data, aes(x=Transmission)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black", ordered=TRUE)
```

## {-}

Seguimos con el análisis univariante, ahora con "Transmission". Se trata de una variable cualitativa binaria, en la que podemos distinguir entre los coches automáticos y manuales. Una transmisión manual es una caja de cambios que no puede alterar la relación de cambio por sí sola, requiriendo la intervención del conductor para hacer esto y sin embargo, una transmisión automática es una caja de cambios de automóviles u otro tipo de vehículos que puede encargarse por sí misma de cambiar la relación de cambio automáticamente a medida que el vehículo se mueve, liberando así al conductor de la tarea de cambiar de marcha manualmente. Se tienen  muestras 1720 de automáticos y 4299 de manuales. Tenemos la variable como factor en nuestros datos, en este caso, al ser sólo dos valores, es perfecto para nuestro análisis.


## Análisis variable "Owner_Type" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r , message=FALSE, warning=FALSE}
summary(data$Owner_Type)
```

### Histograma

```{r analisis variable Owner_Type, message=FALSE, warning=FALSE}
ggplot(data, aes(x=Owner_Type)) + 
  geom_histogram(stat="count",binwidth = 0.4,  fill="dark blue", colour="black")
```

## {-}

La siguiente variable a analizar es "Owner_Type", que hace referencia a la clase de propietario, es decir, si el conductor está configurado como primer, segundo o tercero. Se trata de una variable cualitativa en la que podemos distinguir entre los valores: First, Second, Third y Fourth&Above. Del valor que menos muestras tenemos es Fourth&Above con 9 de ellas, después, Third con 113, y en Second y First aumentan considerablemente (968 y 4929, respectivamente) por lo que será mucho más preciso el análisis a la hora de correlacionar variables. Realizamos el histograma para apreciar la diferencia entre el número de muestras de cada tipo.

## Análisis variable "Mileage" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Mileage, message=FALSE, warning=FALSE}
summary(data$Mileage)
```

### Boxplot

```{r, message=FALSE, warning=FALSE}
boxplot(data$Mileage, col = "blue")
```

## {-}

Seguimos con el análisis univariante de la variable "Mileage" que hace referencia al kilometraje del coche y está expresado en kilómetros por litro. Se trata de una variable cuantitativa continua que toma muchos y distintos valores que posteriormente agruparemos por intervalo. En nuestros datos está expresada como factor, lo mejor sería convertirlo a integer o float para así poder realizar gráficos para visualizar cada una de las muestras. No tiene sentido trabajarla como factor pero la trabajaremos más adelante. Tampoco se ha realizado el gráfico porque visualmente no ayuda.

## Análisis variable "Engine" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Engine, message=FALSE, warning=FALSE}
summary(data$Engine)
```

### Boxplot

```{r, message=FALSE, warning=FALSE}
boxplot(data$Engine, col = "blue")
```

## {-}

Esta variable, "Engine", hace referencia a la cilindrada del motor. Se trata de una variable cuantitativa discreta y que está como integer en nuestros datos. El mínimo es 72 y el máximo es 5998 siendo la media 1621 y donde el 50% de las muestras las encontramos entre 1198 y 1984.

## Análisis variable "Power" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Power, message=FALSE, warning=FALSE}
summary(data$Power)
```

### Boxplot

```{r , message=FALSE, warning=FALSE}
boxplot(data$Power, col = "blue")
```

## {-}

Esta variable hace referencia a la potencia del motor. Se trata de una variable cuantitativa continua en la que el mínimo es 34.2 y el máximo 560 con media 113.3 y donde el 50% de los datos se encuentran entre 75 y 138. Además, existen 143 valores faltantes que serán de gran importancia en nuestro análisis.

## Análisis variable "Seats" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Seats , message=FALSE, warning=FALSE}
summary(data$Seats)
```

### Histograma

```{r , message=FALSE, warning=FALSE}
hist(data$Seats, col = "blue")
```

### Asientos = 0

No tiene sentido que haya coches con 0 asientos, procedemos a su eliminación
```{r, message=FALSE, warning=FALSE}
data %>% filter(Seats>0) -> data
summary(data$Seats)
```
## {-}

Esta variable "Seats" hace referencia al número de asientos que tiene el coche. Es una variable cuantitativa discreta ya que son valores exactos y además se trata como numeric, que viene perfecto para nuestro análisis. Se aprecia que aparece una de las opciones con Seats=0 cuyo valor es NA, la hemos obviado ya que es imposible que un coche no tenga asientos. La mayoría de los coches poseen 5 asientos y se le acercan también los coches de 7 y 8 plazas, mucho más comunes en personas con muchos hijos o que necesiten los coches para transportar más personas de lo "común".
Si nos fijamos en el summary como hemos dicho antes la media está en 5.28, aproximadamente 5 y contamos con 42 valores NA's.

## Análisis variable "New_Price" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable New_price, message=FALSE, warning=FALSE}
summary(data$New_Price)
```

### NA's %

```{r, message=FALSE, warning=FALSE}
apply(is.na(data[, c(12,13)]), 2, mean)  #porcentaje na por columna 
```

## {-}

New_Price contiene 5195 NA's que conforman el 86% de los valores faltantes en esa columna. Más adelante la eliminaremos del train set cuando hagamos la división.

## Análisis variable "Price" {.tabset .tabset-fade .tabset-pills}

### Summary

```{r analisis variable Price, message=FALSE, warning=FALSE}
summary(data$Price)
```

### Histograma + Densidad

Visualizamos Price en escala logaritmica.

```{r, message=FALSE, warning=FALSE}
data %>% ggplot(aes(x=Price)) +
  ggtitle("Precio") +
  theme_fivethirtyeight() +
  geom_histogram(aes(y=..density..), color="white", fill="dark blue", bins = 50) + 
  geom_density() +
  scale_x_log10()
```

## {-}

La variable Price será nuestra variable respuesta. Trataremos de estimar el precio de un coche en base a todas las demás características. El precio está expresado en Rupias y en nuestros datos como numeric. Haciendo un summary vemos que el mínimo precio es de 0.440 y el máximo de 160 que al estar tan lejos de la media se entiende que hay pocos coches que tengan un precio tan alto. La media está en 9.47 rupias y el 50% de los coches tienen un precio de entre 3.5 y 9.95. 

Una vez analizadas tanto las variables de manera univariante como sus outliers, ahora ya podemos separar el dataset en sets para train y test.

# SEPARACION TRAIN/TEST

Procedemos a separar el dataset en sets de *_train_* y de *_test_*

```{r train test sets, message=FALSE, warning=FALSE} 
# 80% del tamaño de la muestra
smp_size <- floor(0.8 * nrow(data))
# establecemos la semilla para que su partición sea reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
rm(train_ind)
```


# DETECCIÓN, TRATAMIENTO E IMPUTACIÓN DE DATOS 

## {.tabset .tabset-fade .tabset-pills}

### Tabla NA's

A continuación vamos a ver la cantidad de valores perdidos con la función md.pattern de la librería *mice*

```{r missing data, results='hide', message=FALSE, warning=FALSE}
md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

### NA's por columna

Vamos a buscar en qué variables y en qué medida de nuestro conjunto de datos hay algún dato del tipo `NA`

Porcentaje de NA's por columna

```{r encontrar NAs en el caso de que aparezcan en nuestro conjunto, message=FALSE, warning=FALSE}
apply(is.na(train), 2, mean) #porcentaje NA por columna  
#apply(is.na(train), 2, which)  # Posición de NA por columna
#p= dim(train)[2]
#number_na = apply(train[,c(p-1,p)],1,function(x) sum(is.na(x)))
#table(number_na)
```
Número de NA's por columna

```{r , message=FALSE, warning=FALSE}
colSums(is.na(train))
```

Se observa claramente que al 86% de los registros les falta datos de la variable New_price, por lo que vamos a proceder a su eliminación ya que la imputación de NA es inviable. También eliminaremos la columna 'X' ya que no es más que el indice duplicado.

### Eliminación Columnas

Eliminamos las columnas New_Price y X
```{r , message=FALSE, warning=FALSE}
train %>% select(-New_Price) -> train
train %>% select(-X) -> train
```

Podemos volver a analizar los valores faltantes ahora que hemos eliminado la columna New_Price

```{r missing data2, results='hide', message=FALSE, warning=FALSE}
md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

Como podemos ver ahora:
-85 coches que tienen valores faltantes en las columnas Power
-2 coches que no tienen datos de Mileage

### Datos faltantes

Los datos faltantes se podrían rellenar buscando información en internet o completandolos con los datos de coches con el mismo nombre. Vamos a probar esto.

```{r, message=FALSE, warning=FALSE}
train %>% filter(is.na(Engine) | is.na(Seats) | is.na(Power) | is.na(Mileage)) %>% 
  pull(Name) %>% unique() -> missing_cars #guardamos los coches que tienen faltantes
train %>% group_by(Name) %>% 
  fill(Engine, Power, Seats, Mileage) %>% ungroup() -> train #sacamos de data esos coches

md.pattern(train, plot = TRUE, rotate.names=TRUE)
```

Se puede apreciar que el número de valores faltantes disminuye pero no de forma significativa. Aún tenemos más de 70 coches con valores faltantes y dado que la mayoría tiene muchas especificaciones dentro de su propio nombre, buscar los valores que faltan coche por coche es tedioso y puede que no afecte mucho al resultado final del análisis. 
Procedemos a eleminiar todos los registros con valores faltantes en lugar de imputarlos.

```{r, message=FALSE, warning=FALSE}
train %>% drop_na() -> train
```

## {-}


# TRANSFORMACIÓN Y CREACIÓN DE VARIABLES 

## {.tabset .tabset-fade .tabset-pills}

### Variable Make

Por lo antes comentado de los nombres, vamos a crear una nueva variable llamada *Make*, la razón de crear esta variable es la de separar la Marca del tipo de coche ya que ambos estan juntos en la variable *Name*.

```{r new variable, message=FALSE, warning=FALSE}
str_split(train$Name, " ", simplify=TRUE) %>% subset(select=1) %>% unique() -> car_makes
car_makes[car_makes=="Land"] <- "Land Rover" #Anomalía en los datos
car_makes_regex <- paste(car_makes, collapse="|")
str_extract(train$Name, car_makes_regex) -> make
train %>% mutate(Make = str_to_title(make)) -> train
```

### Variables Kmpl y Kmpkg

Al inicio detectamos que había dos unidades de medida en la variable Mileage.

Los kmpkg son en realidad una métrica para los combustibles de gas licuado. Así que no está justificado convertirlos en unidades de kmpl. 
Los coches eléctricos ni siquiera tienen la métrica del kilometraje en este conjunto de datos, algo que es de esperar.

Por lo tanto, vamos a crear dos variables llamadas kmpkg y kmpl, para que la variable Mileage pueda tener diferentes coeficientes para los tipos de combustible diesel/gasolina y GNC/GLP. 
La lógica es que kmpkg sólo tendrá valores no nulos para los coches alimentados con GNC/GPL, por lo que los coeficientes se ajustarán/aprenderán sólo de esas observaciones y viceversa.

```{r, message=FALSE, warning=FALSE}
train %>% 
    mutate(kmpl = ifelse(Fuel_Type=="Diesel" | Fuel_Type=="Petrol", Mileage, 0)) %>%
    mutate(kmpkg = ifelse(Fuel_Type=="CNG" | Fuel_Type=="LPG", Mileage, 0)) %>%
    select(-Mileage) -> train
```

## {-}

# SELECCION DE VARIABLES 

## {.tabset .tabset-fade .tabset-pills}

### Variable Respuesta

Nuestra variable respuesta va a ser: *Price*
Por lo que en primer lugar, vamos a ver la distribución de esta variable.

```{r, message=FALSE, warning=FALSE}
train %>% ggplot() + 
  geom_histogram(aes(Price, ..density..), bins=80) + 
  geom_density(aes(Price))
```

La distrubución es demasiado sesgada, volvemos a probar usando una distribución logaritmica

```{r, message=FALSE, warning=FALSE}
train %>% ggplot() + 
  geom_histogram(aes(Price, ..density..), bins=80) + 
  geom_density(aes(Price)) +
  scale_x_log10()
```

Esto remedia la asimetría, por lo que transformaremos la variable antes de modelarla. Para la exploración seguiremos utilizando la escala logarítmica, pero no transformaremos realmente la variable *Price* en el conjunto de datos.

### Correlación 

Para analizar la correlación entre variables mostramos tres gráficos (utilizando las librerías `ellipse` y `corrplot`):

- En el primero lo que haremos será ver la correlación con elipses. Cuanto más circular sea menos correlación habrá entre las variables y cuanto más recta más correlación habrá.

- En el segundo lo que haremos será ver la correlación con una escala numérica de 0 a 1. El 0 indica ausencia de relación lineal y el 1 indica relación lineal perfecta.

- En el tercero, usando la escala que tenemos en el lateral, vemos que cuanto más oscuro y grande es el círculo, mayor relación lineal hay (azul si es positiva y rojo si es negativa), y cuanto más claro y pequeño es el círculo, menor relación lineal hay (azul si es positiva y rojo si es negativa).

Lo hacemos únicamente, de momento, con las variables numéricas.

```{r corr 2, message=FALSE, warning=FALSE}
corrplot(cor(train[, c(3,4, 8, 9, 11, 13, 14)]), method = "ellipse") 
corPlot(train[, c(3,4, 8, 9, 11, 13, 14)], cex = 1.2, main = "Matriz de correlación")
corrplot(cor(train[, c(3,4, 8, 9, 11, 13, 14)]),method = "circle",       order = "hclust",         hclust.method = "ward.D",
         addrect =2,rect.col = 3,rect.lwd = 3)  
```

Con estos gráficos podemos ver rápidamente cuáles son las variables más correlacionadas con la variable respuesta y entre ellas mismas. Las que más pueden afectar a nuestra variable respuesta son Engine y Power. Year y kmpl tienen una correlación de 0.3 y sin embargo kmpkg no tiene nada de correlación al igual que los kilómetros recorridos que tenga el coche por lo que no servirán de mucho para nuestro análisis.

Vemos más detalladamente la correlación con cada variable, esta parte es fundamental para la selección de variables que posteriormente haremos en la regresión del modelo que creemos.

### Year + Price

```{r analisis Year + Price, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Year, train$Price)) +
  geom_boxplot(aes(group=Year)) +
  geom_jitter(alpha=0.1) +
  geom_smooth(method="loess") +
  scale_y_log10()
```
```{r,message=FALSE, warning=FALSE}
data.frame(train$Year, train$Price) %>% chart.Correlation()
```

Se aprecia cierta correlación entre el año de fabricación del modelo y el precio del coche. Cuanto más nuevo es, más valor tiene. No influye de manera significativa y drástica año a año pero si aumenta, aunque sea en poca proporción, el valor del coche.

### Make + Price

```{r analisis Make + Price, message=FALSE, warning=FALSE}
grid.arrange(
  ggplot(train, aes(reorder(Make, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Make, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Lo que podemos ver es que hay mas marcas baratas que caras. Las marcas más caras son las de coches de lujo y hay muy pocos coches de este tipo en este dataset. 
Por otro lado, hay muchos coches de gama media de precio decente, como Hyundai y Maruti. Esto nos da una pista de que la marca de un coche puede determinar su precio.

### Location + Price

```{r análisis Location+Price, message=FALSE, warning=FALSE}
ggplot(train, aes(Location, Price))+geom_boxplot(aes(group=Location))+geom_jitter(alpha=0.1)+geom_smooth(method="loess")+scale_y_log10()
grid.arrange(
  ggplot(train, aes(reorder(Location, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Location, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Los coches disponibles están bien distribuidos en cada una de las ciudades de la India y como se aprecia, no tiene mucha relación el lugar de venta con el precio que cuesta.

### Kilometers Driven + Price

```{r analisis Kilometers_Driven+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Kilometers_Driven, Price))+
  geom_boxplot(aes(group=Kilometers_Driven))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()
```
```{r,message=FALSE, warning=FALSE}
plot(train$Kilometers_Driven, train$Price)
```
```{r, message=FALSE, warning=FALSE}
data.frame(train$Kilometers_Driven, train$Price) %>%
  chart.Correlation()
```

La empresa de ventas de coches parece haber decidido que no es relevante el número de kilómetros recorridos con respecto al precio. Mientras el coche circule y esté en óptimas condiciones, no se tiene en cuenta el número de kilómetros que suele estar relacionado con el año de fabricaión del coche.

### Fuel Type + Price

```{r análisis FuelType+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Fuel_Type, Price))+
  geom_boxplot(aes(group=Fuel_Type))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(Fuel_Type, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Fuel_Type, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Lo primero que se aprecia es que la mayoria de coches son de diésel y gasolina y además son los que mayor precio tienen. Un coche diésel es más caro que uno de gasolina generalmente básicamente por el consumo que realiza cada uno de ellos.

### Transmission + Price

```{r análisis Transmission+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Transmission, Price))+
  geom_boxplot(aes(group=Transmission))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(Transmission, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Transmission, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

En este dataset hay más coches manuales que automáticos como se aprecia pero los automáticos son más caros. Esto es porque ofrecen mayor comodidad, la conducción es más segura y atenta al tráfico al no tener que estar pendiente del pedal y la palanca, aparte de la diferencia de consumo entre ambos.

### Owner Type + Price

```{r análisis OwnerType + Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Owner_Type, Price))+geom_boxplot(aes(group=Owner_Type))+geom_jitter(alpha=0.1)+geom_smooth(method="loess")+scale_y_log10()
grid.arrange(
  ggplot(train, aes(reorder(Owner_Type, Price, median), Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(Owner_Type, Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

La mayoría de coches de segunda mano son los que han pasado ya por un conductor o en su defecto por dos. Antigüedad de 3 dueños es poco común y se da pocas veces generalmente. Está estrechamente relacionado el precio con los dueños que ha tenido el coche, siendo más caros los que menos dueños han tenido, lógicamente.

### Engine + Price

```{r análisis Engine+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(Engine, Price))+
  geom_boxplot(aes(group=Engine))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$Engine, train$Price) %>% 
  chart.Correlation()
```

Atendiendo a los gráficos se tiene una alta correlación entre la cilindrada del motor y el precio del coche. 
Cuanto mayor sea la cilindrada del motor, mayor será el precio del coche ya que es un factor determinante en la potencia del coche y en el combustible que éste consume.

### Power + Price

```{r análisis Power+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Power, train$Price))+
  geom_boxplot(aes(group=train$Power))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$Power, train$Price) %>% chart.Correlation()
```

La potencia del motor está relacionada altamente y de manera lineal con el precio del coche. A mayor potencia, mayor será el precio de compra. 

### Seats + Price

```{r  análisis Seats+Precio, message=FALSE, warning=FALSE}
ggplot(train, aes(train$Seats, train$Price))+
  geom_boxplot(aes(group=train$Seats))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

grid.arrange(
  ggplot(train, aes(reorder(train$Seats, train$Price, median), train$Price)) +
    geom_boxplot() +
    scale_y_log10() + 
    coord_flip(),
  ggplot(train, aes(reorder(train$Seats, train$Price, median))) + 
    geom_bar(stat="count") +
    theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    coord_flip(),
      ncol=3, nrow=1,
      layout_matrix=t(c(1,1,2))
)
```

Se aprecia una buena e igualada dstribución en el precio de los coches en función del número de asientos que posean. Los más caros son los biplaza debido, seguramente, a que las marcas de lujo como Lamborguini y Bently venden sobretodo deportivos biplaza. Es evidente que el número de plazas en el coche a igualdad de condiciones, afectará pero no parece altamente significativo en este dataset. También es cierto que coches biplaza sólo tenemos 11 en este dataset y es dificil sacar una conclusión con certeza.

### Kmpl/Kmpkg + Price

```{r análisis kmpl+Price, message=FALSE, warning=FALSE}
ggplot(train, aes(train$kmpl, train$Price))+
  geom_boxplot(aes(group=train$kmpl))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$kmpl, train$Price) %>% chart.Correlation()
```

```{r análisis kmpkg+ Price, message=FALSE, warning=FALSE} 
ggplot(train, aes(train$kmpkg, train$Price))+
  geom_boxplot(aes(group=train$kmpkg))+
  geom_jitter(alpha=0.1)+
  geom_smooth(method="loess")+
  scale_y_log10()

data.frame(train$kmpkg, train$Price) %>% chart.Correlation()
```


La relación entre el kilometraje y el precio no va a ser diferencial ni significativa en nuestro análisis. 

En conclusión, las variables que más afectan a nuestra variable respuesta, el precio, son: la marca, el tipo de combustible, el tipo de transmision, la cilindrada y la potencia y en menor medida pero que también analizaremos: el año de fabricación, los dueños que ha tenido y el número de plazas que posee

### Engine + Power

```{r}
plot(train$Engine,train$Power)
train %>% select(Price, Engine, Power) %>% mutate(Price=log10(Price)) %>% cor() %>% ggcorrplot(lab=TRUE)
```
Existe una alta correlación entre las variables Engine y Power, al igual que en el mundo real, la cilindrada del motor determina la potencia de éste. Es por eso que después en el modelo nos valdrá con incluir solamente una de las dos. 

## {-}

# AJUSTE, INTERPRETACIÓN Y DIAGNOSIS DEL MODELO DE REGRESION LINEAL MÚLTIPLE

```{r, message=FALSE, warning=FALSE}
cor(train[, c(3, 8, 9, 11)])
```


```{r, message=FALSE, warning=FALSE}
#Trabajos con las variables cuantitativas
reg.fit.selec=regsubsets(x=train[, c(3, 8, 9, 10)], y=train$Price)
reg.summary=summary(reg.fit.selec)
summary(reg.fit.selec)
```

Vamos a proceder a seleccionar ls variables con las que vamos a hacer la regresión, empezamos con las variables cuantitativas unicamente.
El mejor modelo con una variable explicativa, sería el que contiene Power.
El mejor modelo con dos variables explicativas, sería el que contiene Year y Power
El mejor modelo con tres, el que contiene Year, Power y Seats
El mejor modelo con cuatro variables es el que contiene las cuatro.

### Estadisticos R²:
```{r criterios, message=FALSE, warning=FALSE}
#names(reg.summary) #criterios o estadisticos para comparar modelos
#Estadisticos R^2:
reg.summary$rsq
```

### Estadisticos R² ajustado:

```{r, message=FALSE, warning=FALSE}
#Estadisticos R^2 ajustado:
reg.summary$adjr2
```

El mejor modelo es el que maximiza la R² y la R² ajustada. En este caso y teniendo en cuenta sólo 4 covariables, parece claro seleccionar el modelo con 4 covariables aunque también sería correcto selecionar un modelo con 3 de ellas.

```{r, message=FALSE, warning=FALSE, results='hide'}
par(mfrow=c(1,2))
plot(reg.summary$rss ,xlab="Numero de variables ",ylab="RSS",
     type="l") #aqui usamos rss
plot(reg.summary$adjr2 ,xlab="Numero de variables ",
     ylab="R2 ajustada",type="l")
num_var <- which.max(reg.summary$adjr2)
points(num_var,reg.summary$adjr2[num_var], col="red",cex=2,pch=20)
```

### CP

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$cp
plot(reg.summary$cp ,xlab="Numero de variables ",ylab="Cp",type="l")
num_var <- which.min(reg.summary$cp)
points(num_var,reg.summary$cp[num_var], col="red",cex=2,pch=20)
``` 

### BIC

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$bic
plot(reg.summary$bic ,xlab="Numero de variables ",ylab="Bic",type="l")
num_var <- which.min(reg.summary$bic)
points(num_var,reg.summary$bic[num_var], col="red",cex=2,pch=20)
```

Tanto en CP como en BIC el número óptimo de variables para seleccionar es el que minimiza la función.
Una vez utilizados los criterios y estadísticos para seleccionar las variables significativas, en este caso cuantitativas, decidimos seleccionar las cuatro variables para nuestro modelo de regresión.


Ahora vamos a realizar lo mismo pero añadiendo las variables que estan como factor en nuestros datos.

```{r, message=FALSE, warning=FALSE}
#x=model.matrix(~Year+Transmission+Fuel_Type+Owner_Type+Engine+Power+Seats+Make,data=train)
x=model.matrix(~Year+Transmission+Owner_Type+Engine+Power+Seats+Make,data=train)
#x <- model.matrix(Price~., train)
reg.fit.select=regsubsets(x[,-1], y=train$Price) #Quitamos la intercptación que por defecto se construye en la matriz de diseño, ya que la funcion regsubsets tambien la incluye por defecto
reg.summary= summary(reg.fit.select)
reg.summary
```

El modelo seleccionado es el que incluye las variables Year, Power y los siguientes valores de Make: Audi, BMW, Lamborghini, Land Rover, Mercedes Benz Y Jaguar.
Al intentar incluir la variable Fuel_Type nos aparece redundancia pero es una variable con importante correlación y que consideraremos al crear el modelo de regresión. Una vez añadidas las variables factor, vamos a ver que variables seleccionamos.

```{r , message=FALSE, warning=FALSE}
#Vamos a buscar el mejor modelo 
reg.summary$adjr2 
plot(reg.summary$adjr2 ,xlab="Numero de variables ", ylab="R2 ajustada",type="l")
num_var <- which.max(reg.summary$adjr2)
points(num_var,reg.summary$adjr2[num_var], col="red",cex=2,pch=20)
```

```{r, message=FALSE, warning=FALSE, results='hide'}
reg.summary$cp
plot(reg.summary$cp ,xlab="Numero de variables ",ylab="Cp",type="l")
var <- which.min(reg.summary$cp)
points(var,reg.summary$cp[var], col="red",cex=2,pch=20)
```

```{r, message=FALSE, warning=FALSE}
reg.summary$bic
plot(reg.summary$bic ,xlab="Numero de variables ",ylab="Bic",type="l")
var <- which.min(reg.summary$bic)
points(var,reg.summary$bic[var], col="red",cex=2,pch=20)
```

Gracias a los métodos para saber cual es el mejor modelo y al summary se obtiene que el mejor modelo de regresión lineal multiple es el que contiene 8 covariables: Year, Power y varios tipos de Marca. Teniendo en cuenta la variable Fuel_Type también, vamos a añadirla al modelo.

De nuestro análisis hemos obtenido información:

-El año de fabricación del coche y la marca dan una indicación visual y un efecto significativo en el precio.

-La potencia se correlaciona mejor con el precio que con el motor.

-Además de estas variables, no se muestra ninguna indicación visual clara en las demás.

Entonces, podríamos estar interesados en construir un modelo lineal usando estas variables, simplemente:

```{r mod selec, message=FALSE, warning=FALSE}
mod_selec=lm(log10(Price) ~ Year+Fuel_Type+Power+Make,data=train)
summary(mod_selec)
```

Vamos ahora a chequear el modelo:

```{r, message=FALSE, warning=FALSE}
print(paste("R squared:", summary(mod_selec)$r.squared))
print(paste("MSE:", mean(mod_selec$residuals^2)))
plot(mod_selec)
```

```{r, message=FALSE, warning=FALSE}
dwt(mod_selec, alternative = "two.sided")
```


En el gráfico de *Residuos vs Ajustes* se observa que la media de los residuos es prácticamente cero, luego la linealidad del modelo no se viola.

La *varianza* de los residuos parece constante por lo que tampoco se viola la homocedasticidad del modelo, el ajuste es bueno.
Lo que si se observa es la aparición de puntos candidatos a ser outliers.

Con el *Q-Q Plot* vemos que los residuos no tienen una distribución normal en las colas. Por tanto no se puede asumir que los estimadores de los coeficientes tengan una distrbución normal.

En el gráfico de *Residuals vs Leverage* observamos que hay puntos con alto leverage pero ninguno cae fuera de los limites de la distancia de Cook.

Además, gracias al *Darwin test* sabemos que no hay evidencias de autocorrelación.

Parece que no hay violaciones a los supuestos de OLS. Nuestro modelo parece decente, con un R cuadrado de aproximadamente el 90%. Realmente bueno ya para un modelo lineal. OLS son las distancias verticales entre las respuestas observadas en la muestra y las respuestas del modelo. 



```{r, message=FALSE, warning=FALSE}
AIC(lm(log(Price)~Power,data=train))
AIC(lm(log(Price)~Power+Year,data=train))
AIC(lm(log(Price)~Power+Year+Make,data=train))
AIC(lm(log(Price)~Fuel_Type+Power+Year+Make,data=train))
```

```{r, message=FALSE, warning=FALSE}
BIC(lm(log(Price)~Power,data=train))
BIC(lm(log(Price)~Power+Year,data=train))
BIC(lm(log(Price)~Power+Year+Make,data=train))
BIC(lm(log(Price)~Fuel_Type+Power+Year+Make,data=train))
```

Según los criterios AIC y BIC el mejor modelo es el que contiene las 4 covariables. El criterio BIC suele ser más parsimonioso pero también detecta que el mejor modelo es el de cuatro variables: Fuel_Type, Power, Year y Make.




